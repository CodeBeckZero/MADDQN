{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU support) is not available. PyTorch is running on CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cleandata\n",
    "import stockenv \n",
    "import sys\n",
    "import pandas as pd\n",
    "import agentperform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "from agents.ddqn import DDQN\n",
    "\n",
    "\n",
    "pwd = \"C:/programming/MADDQN\"\n",
    "sys.path.append(pwd)\n",
    "\n",
    "# Input Data Location, File Name, Stock name for labels\n",
    "import_path = pwd + \"/input_data\"\n",
    "\n",
    "# Output Path Location for CSV export\n",
    "export_path = pwd + \"/output_data\"\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device\n",
    "    device = torch.cuda.current_device()\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"CUDA (GPU support) is not available. PyTorch is running on CPU.\")\n",
    "\n",
    "\n",
    "stock_inputs ={'DJI':'^DJI_daily.csv',\n",
    "               'NDAQ': '^IXIC_daily.csv',\n",
    "               'SP500': '^SPX_daily.csv',\n",
    "               'AAPL': 'AAPL_daily.csv',\n",
    "               'AMZN': 'AMZN_daily.csv',\n",
    "               'GOOGL': 'GOOGL_daily.csv',\n",
    "               'MSFT': 'MSFT_daily.csv',\n",
    "               'SINE': 'sine_wave_daily.csv',\n",
    "               'FORD': 'F_daily.csv',\n",
    "               'JNJ': 'JNJ_daily.csv',\n",
    "               'NEE': 'NEE_daily.csv',\n",
    "               'PFE': 'PFE_daily.csv',\n",
    "               'TSLA': 'TSLA_daily.csv',\n",
    "               'USIDX': '^USIDX_daily.csv'}\n",
    "\n",
    "# Training Inputs\n",
    "trn_keys = ['DJI','NDAQ','SP500']\n",
    "training_range = (0,2500)\n",
    "validation_range = (2500,2750)\n",
    "\n",
    "ALPHA = 0.1\n",
    "GAMMA = 0.9\n",
    "\n",
    "# Testing Inputs\n",
    "tst_keys = stock_inputs.keys()\n",
    "testing_range = (2750,3000)\n",
    "\n",
    "environments = {}\n",
    "\n",
    "for name, file in stock_inputs.items():\n",
    "    temp_df = cleandata.YAHOO_csv_input(file,import_path)\n",
    "    temp_norm_df = cleandata.normalize_df_ohlcv_by_row_range(temp_df,training_range[0],training_range[1])\n",
    "    environments[name] = stockenv.ContinuousOHLCVEnv(name,ohlcv_data=temp_norm_df.to_numpy(),\n",
    "                                  stock_price_data=temp_df['close'].to_numpy(),\n",
    "                                  commission_rate=0.005)\n",
    "\n",
    "\n",
    "# Define a reward function outside the Environment class\n",
    "def norm_min_1(norm_num):\n",
    "    \"\"\"\n",
    "    Normalize values with respect to a mean of 0 by scaling them to be centered around 1.\n",
    "    \n",
    "    Parameters:\n",
    "    - norm_num: Input number to be normalized.\n",
    "\n",
    "    Returns:\n",
    "    - Normalized value: If input is close to zero, output is around 1. \n",
    "      For inputs -6 to -2 or 2 to 6, output approximates the range 6 to 2. \n",
    "      Six standard deviations is approximately 99.9999998%.\n",
    "    \"\"\"\n",
    "    if norm_num < -2:\n",
    "        return -norm_num\n",
    "    if norm_num > 2:\n",
    "        return norm_num\n",
    "    if norm_num == 0:\n",
    "        return 1\n",
    "    if norm_num > 0:\n",
    "        return 0.5 * norm_num + 1\n",
    "    if norm_num < 0:\n",
    "        return -0.5 * norm_num + 1\n",
    "\n",
    "def MADDQN_return_reward(env):\n",
    "    n = 5 # How many days in the future\n",
    "    \n",
    "    \n",
    "    current_price = env.stock_price_data[env.current_step]\n",
    "    \n",
    "    # Check if there are enough elements for the future prices\n",
    "    if len(env.ohlcv_raw_data) < env.current_step + n:\n",
    "        raise ValueError(\"Not enough OHLCV data for the future prices\")\n",
    "    \n",
    "    tomorrows_price = env.stock_price_data[env.current_step+n]\n",
    "    position = env.position\n",
    "    reward = (((tomorrows_price - current_price)/current_price))*position\n",
    "    opp_cost = 0.0002*(1-position) # Assuming risk-free return of 5% / 252 trading days + np.mean() in agents counts zeros\n",
    "    \n",
    "    return (reward - opp_cost)*100\n",
    "\n",
    "def return_reward(env):\n",
    "    n = 10 # How many days in the future\n",
    "    \n",
    "    \n",
    "    current_price = norm_min_1(env.ohlcv_raw_data[env.current_step,3])\n",
    "    \n",
    "    # Check if there are enough elements for the future prices\n",
    "    if len(env.ohlcv_raw_data) < env.current_step + n:\n",
    "        raise ValueError(\"Not enough OHLCV data for the future prices\")\n",
    "    \n",
    "    tomorrows_price = norm_min_1(env.ohlcv_raw_data[env.current_step:env.current_step+n,3].mean())\n",
    "    position = env.position\n",
    "    reward = (((tomorrows_price - current_price)/current_price))*position\n",
    "    \n",
    "    opp_cost = 0.0002*(1-position) # Assuming risk-free return of 5% / 252 trading days\n",
    "    \n",
    "    return 100*(reward - opp_cost)\n",
    "\n",
    "def risk_reward(env):\n",
    "    \"\"\"\n",
    "    Calculate the risk-reward ratio based on historical price data and current position in the environment.\n",
    "\n",
    "    Args:\n",
    "    - env: Environment object containing OHLCV raw data and position information.\n",
    "\n",
    "    Returns:\n",
    "    - float: Risk-reward ratio.\n",
    "    \"\"\"\n",
    "    n = 33  # How many days in the future\n",
    "\n",
    "    current_price = env.ohlcv_raw_data[env.current_step, 3]\n",
    "    \n",
    "    # Check if there are enough elements for the future prices\n",
    "    if len(env.ohlcv_raw_data) < env.current_step + n:\n",
    "        raise ValueError(\"Not enough OHLCV data for the future prices\")\n",
    "    \n",
    "    tomorrows_price = env.ohlcv_raw_data[env.current_step:env.current_step+n, 3]\n",
    "    position = env.position\n",
    "    \n",
    "    rewards = (tomorrows_price - current_price) / current_price\n",
    "    \n",
    "    rewards_mean = np.mean(rewards)  # Calculate mean using NumPy's mean function\n",
    "    rewards_std = np.std(rewards)  # Calculate standard deviation using NumPy's std function\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (rewards_mean / rewards_std) * position\n",
    "   \n",
    "def linear_decay(initial_epsilon, final_epsilon, current_epoch, total_epochs):\n",
    "    if initial_epsilon == final_epsilon:\n",
    "        return initial_epsilon\n",
    "    elif total_epochs == 1:\n",
    "        return final_epsilon\n",
    "    else:\n",
    "        rate_of_change = (final_epsilon - initial_epsilon) / (total_epochs-1)\n",
    "        current_epsilon = np.round((initial_epsilon - rate_of_change) + (rate_of_change * current_epoch),3)\n",
    "        \n",
    "        if current_epsilon > initial_epsilon or current_epsilon < final_epsilon:\n",
    "            raise ValueError(f'Epsilon value ({current_epsilon}) out of valid range ({initial_epsilon}:{final_epsilon})')\n",
    "    \n",
    "        return current_epsilon \n",
    "\n",
    "def decimal_to_text(decimal_number):\n",
    "    # Remove the decimal point and convert to integer\n",
    "    integer_part = int(decimal_number * 1000)\n",
    "    # Convert the integer to text\n",
    "    text_representation = str(integer_part)\n",
    "    return text_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-22 20:38:33,060] A new study created in memory with name: no-name-3c65f414-753f-48f4-933a-c74659028e7a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DJI ENV: Agent REWARD_DDQN_AGENT added\n",
      "DJI ENV: Agent REWARD_DDQN_AGENT assigned as decision agent\n",
      "NDAQ ENV: Agent REWARD_DDQN_AGENT added\n",
      "NDAQ ENV: Agent REWARD_DDQN_AGENT assigned as decision agent\n",
      "SP500 ENV: Agent REWARD_DDQN_AGENT added\n",
      "SP500 ENV: Agent REWARD_DDQN_AGENT assigned as decision agent\n",
      "AAPL ENV: Agent REWARD_DDQN_AGENT added\n",
      "AAPL ENV: Agent REWARD_DDQN_AGENT assigned as decision agent\n",
      "AMZN ENV: Agent REWARD_DDQN_AGENT added\n",
      "AMZN ENV: Agent REWARD_DDQN_AGENT assigned as decision agent\n",
      "GOOGL ENV: Agent REWARD_DDQN_AGENT added\n",
      "GOOGL ENV: Agent REWARD_DDQN_AGENT assigned as decision agent\n",
      "MSFT ENV: Agent REWARD_DDQN_AGENT added\n",
      "MSFT ENV: Agent REWARD_DDQN_AGENT assigned as decision agent\n",
      "SINE ENV: Agent REWARD_DDQN_AGENT added\n",
      "SINE ENV: Agent REWARD_DDQN_AGENT assigned as decision agent\n",
      "FORD ENV: Agent REWARD_DDQN_AGENT added\n",
      "FORD ENV: Agent REWARD_DDQN_AGENT assigned as decision agent\n",
      "JNJ ENV: Agent REWARD_DDQN_AGENT added\n",
      "JNJ ENV: Agent REWARD_DDQN_AGENT assigned as decision agent\n",
      "NEE ENV: Agent REWARD_DDQN_AGENT added\n",
      "NEE ENV: Agent REWARD_DDQN_AGENT assigned as decision agent\n",
      "PFE ENV: Agent REWARD_DDQN_AGENT added\n",
      "PFE ENV: Agent REWARD_DDQN_AGENT assigned as decision agent\n",
      "TSLA ENV: Agent REWARD_DDQN_AGENT added\n",
      "TSLA ENV: Agent REWARD_DDQN_AGENT assigned as decision agent\n",
      "USIDX ENV: Agent REWARD_DDQN_AGENT added\n",
      "USIDX ENV: Agent REWARD_DDQN_AGENT assigned as decision agent\n",
      "Directory 'C:/programming/MADDQN/output_data/REWARD_DDQN_AGENT/3FC256_TANH_BT10BF500_Q1_TGT30_LR0' created successfully.\n",
      "REWARD_DDQN_AGENT: Training Initialized on DJI[0:2500] -> Validation on DJI[2500:2750]\n",
      "REWARD_DDQN_AGENT: EP 1 of 100 Finished -> ΔQ1 = 0.12, ΔQ2 = 0.20 | ∑R = 103.82, μR = 0.04 σR = 1.75 | Max: val_ror = 1.07 -> New Target Established 1.07 - Reset Early Stopping                        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-04-22 20:39:12,053] Trial 0 failed with parameters: {'hidden_layers': 3, 'hidden_size': 256, 'update_q_freq': 1, 'update_tgt_freq': 30, 'activation_function': 'TANH', 'opt_lre': 0.00010869154827561221, 'buffer_size': 500, 'batch_size': 10} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\beckm\\AppData\\Local\\Temp\\ipykernel_22552\\589820524.py\", line 85, in objective\n",
      "    best_ddqn_agent.train(start_idx=training_range[0],\n",
      "  File \"c:\\Programming\\MADDQN\\agents\\ddqn.py\", line 194, in train\n",
      "    tot_reward, mean_reward, std_reward, loss = self._play_episode(epsilon, update_q_freq, update_tgt_freq, 'training')\n",
      "                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Programming\\MADDQN\\agents\\ddqn.py\", line 290, in _play_episode\n",
      "    self.Q1_tgt_nn = self._create_tgt_nn(self.Q1_nn,self.device)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Programming\\MADDQN\\agents\\ddqn.py\", line 350, in _create_tgt_nn\n",
      "    target_network = copy.deepcopy(Q_nn)\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 172, in deepcopy\n",
      "    y = _reconstruct(x, memo, *rv)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 271, in _reconstruct\n",
      "    state = deepcopy(state, memo)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 146, in deepcopy\n",
      "    y = copier(x, memo)\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 231, in _deepcopy_dict\n",
      "    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 172, in deepcopy\n",
      "    y = _reconstruct(x, memo, *rv)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 297, in _reconstruct\n",
      "    value = deepcopy(value, memo)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 172, in deepcopy\n",
      "    y = _reconstruct(x, memo, *rv)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 271, in _reconstruct\n",
      "    state = deepcopy(state, memo)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 146, in deepcopy\n",
      "    y = copier(x, memo)\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 231, in _deepcopy_dict\n",
      "    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 172, in deepcopy\n",
      "    y = _reconstruct(x, memo, *rv)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 297, in _reconstruct\n",
      "    value = deepcopy(value, memo)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 172, in deepcopy\n",
      "    y = _reconstruct(x, memo, *rv)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 271, in _reconstruct\n",
      "    state = deepcopy(state, memo)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 146, in deepcopy\n",
      "    y = copier(x, memo)\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 231, in _deepcopy_dict\n",
      "    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 172, in deepcopy\n",
      "    y = _reconstruct(x, memo, *rv)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 297, in _reconstruct\n",
      "    value = deepcopy(value, memo)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py\", line 153, in deepcopy\n",
      "    y = copier(memo)\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\torch\\nn\\parameter.py\", line 58, in __deepcopy__\n",
      "    result = type(self)(self.data.clone(memory_format=torch.preserve_format), self.requires_grad)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-04-22 20:39:12,062] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 149\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mean\n\u001b[0;32m    148\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 149\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest value: \u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_value)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest params: \u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[0;32m     63\u001b[0m             study,\n\u001b[0;32m     64\u001b[0m             func,\n\u001b[0;32m     65\u001b[0m             n_trials,\n\u001b[0;32m     66\u001b[0m             timeout,\n\u001b[0;32m     67\u001b[0m             catch,\n\u001b[0;32m     68\u001b[0m             callbacks,\n\u001b[0;32m     69\u001b[0m             gc_after_trial,\n\u001b[0;32m     70\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[2], line 85\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m trn_keys:\n\u001b[0;32m     84\u001b[0m     best_ddqn_agent\u001b[38;5;241m.\u001b[39mset_environment(env)\n\u001b[1;32m---> 85\u001b[0m     best_ddqn_agent\u001b[38;5;241m.\u001b[39mtrain(start_idx\u001b[38;5;241m=\u001b[39mtraining_range[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     86\u001b[0m                 end_idx\u001b[38;5;241m=\u001b[39mtraining_range[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     87\u001b[0m                 training_epsidoes\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     88\u001b[0m                 epsilon_decya_func\u001b[38;5;241m=\u001b[39m linear_decay,\n\u001b[0;32m     89\u001b[0m                 initial_epsilon\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m,\n\u001b[0;32m     90\u001b[0m                 final_epsilon\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     91\u001b[0m                 update_q_freq\u001b[38;5;241m=\u001b[39m sug_update_q_freq,\n\u001b[0;32m     92\u001b[0m                 update_tgt_freq\u001b[38;5;241m=\u001b[39m sug_update_tgt_freq,\n\u001b[0;32m     93\u001b[0m                 save_path \u001b[38;5;241m=\u001b[39m export_path,\n\u001b[0;32m     94\u001b[0m                 val_start_idx \u001b[38;5;241m=\u001b[39m validation_range[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     95\u001b[0m                 val_end_idx \u001b[38;5;241m=\u001b[39m validation_range[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     96\u001b[0m                 early_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     97\u001b[0m                 stop_metric \u001b[38;5;241m=\u001b[39m metric,\n\u001b[0;32m     98\u001b[0m                 stop_patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     99\u001b[0m                 stop_delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m## Export Training Session Data to CSV\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     ddqn_trn \u001b[38;5;241m=\u001b[39m best_ddqn_agent\u001b[38;5;241m.\u001b[39mget_training_episodic_data()\n",
      "File \u001b[1;32mc:\\Programming\\MADDQN\\agents\\ddqn.py:194\u001b[0m, in \u001b[0;36mDDQN.train\u001b[1;34m(self, start_idx, end_idx, training_epsidoes, epsilon_decya_func, initial_epsilon, final_epsilon, val_start_idx, val_end_idx, save_path, early_stop, stop_metric, stop_patience, stop_delta, update_q_freq, update_tgt_freq)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, training_epsidoes\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    189\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m epsilon_decya_func(initial_epsilon, \n\u001b[0;32m    190\u001b[0m                                     final_epsilon,\n\u001b[0;32m    191\u001b[0m                                     episode_num,\n\u001b[0;32m    192\u001b[0m                                     training_epsidoes)\n\u001b[1;32m--> 194\u001b[0m     tot_reward, mean_reward, std_reward, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_play_episode(epsilon, update_q_freq, update_tgt_freq, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Rewards based on Validation Set\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     val_tot_reward, val_avg_reward, val_std_reward, _, ror, cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(val_start_idx,val_end_idx)\n",
      "File \u001b[1;32mc:\\Programming\\MADDQN\\agents\\ddqn.py:290\u001b[0m, in \u001b[0;36mDDQN._play_episode\u001b[1;34m(self, epsilon, update_q_freq, update_tgt_freq, step_type)\u001b[0m\n\u001b[0;32m    288\u001b[0m     tgt_nn_update_bool \u001b[38;5;241m=\u001b[39m total_steps \u001b[38;5;241m%\u001b[39m update_q_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m                    \n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tgt_nn_update_bool:\n\u001b[1;32m--> 290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ1_tgt_nn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_tgt_nn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ1_nn,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ2_tgt_nn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_tgt_nn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ2_nn,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Programming\\MADDQN\\agents\\ddqn.py:350\u001b[0m, in \u001b[0;36mDDQN._create_tgt_nn\u001b[1;34m(self, Q_nn, device)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;124;03mCreate a deep copy of the Q_nn for the target network.\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;66;03m# Serialize the original model's state\u001b[39;00m\n\u001b[1;32m--> 350\u001b[0m target_network \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(Q_nn)\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# Move the copied model to the specified device\u001b[39;00m\n\u001b[0;32m    353\u001b[0m target_network\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m _reconstruct(x, memo, \u001b[38;5;241m*\u001b[39mrv)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m _reconstruct(x, memo, \u001b[38;5;241m*\u001b[39mrv)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:297\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m dictiter:\n\u001b[0;32m    296\u001b[0m         key \u001b[38;5;241m=\u001b[39m deepcopy(key, memo)\n\u001b[1;32m--> 297\u001b[0m         value \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    298\u001b[0m         y[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m _reconstruct(x, memo, \u001b[38;5;241m*\u001b[39mrv)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m _reconstruct(x, memo, \u001b[38;5;241m*\u001b[39mrv)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:297\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m dictiter:\n\u001b[0;32m    296\u001b[0m         key \u001b[38;5;241m=\u001b[39m deepcopy(key, memo)\n\u001b[1;32m--> 297\u001b[0m         value \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    298\u001b[0m         y[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m _reconstruct(x, memo, \u001b[38;5;241m*\u001b[39mrv)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m _reconstruct(x, memo, \u001b[38;5;241m*\u001b[39mrv)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:297\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m dictiter:\n\u001b[0;32m    296\u001b[0m         key \u001b[38;5;241m=\u001b[39m deepcopy(key, memo)\n\u001b[1;32m--> 297\u001b[0m         value \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    298\u001b[0m         y[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(memo)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\torch\\nn\\parameter.py:58\u001b[0m, in \u001b[0;36mParameter.__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m memo[\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)]\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclone(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[0;32m     59\u001b[0m     memo[\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For Objective function, need to create agent name before to link agent with enviornment\n",
    "agent_name = 'REWARD_DDQN_AGENT'\n",
    "agent_path = export_path + '/' + agent_name\n",
    "metric = 'val_ror'\n",
    "\n",
    "for key, env in environments.items():\n",
    "  \n",
    "        env.add_agent(agent_name)\n",
    "        env.set_decision_agent(agent_name)\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # Define the hyperparameters to search over\n",
    "    \n",
    "    ## NN hyperparameters\n",
    "    sug_hidden_layers = trial.suggest_int('hidden_layers', low=1, high=3)\n",
    "    sug_hidden_size = trial.suggest_int('hidden_size', low=64, high=256, step=64)\n",
    "    sug_update_q_freq = trial.suggest_int('update_q_freq',low=1,high=5)\n",
    "    sug_update_tgt_freq = trial.suggest_int('update_tgt_freq',low=10,high=50,step=10)\n",
    "    \n",
    "    ## Function Passing\n",
    "    activation_functions = {\n",
    "    'RELU': nn.ReLU(),\n",
    "    'LRELU': nn.LeakyReLU(),\n",
    "    'GELU': nn.GELU(),\n",
    "    'TANH': nn.Tanh()\n",
    "    }\n",
    "    sug_activation_function_name = trial.suggest_categorical('activation_function', list(activation_functions.keys()))\n",
    "    sug_activation_function = activation_functions[sug_activation_function_name]\n",
    "    \n",
    "    ## Optimizer hyperparameters\n",
    "    sug_opt_lre = trial.suggest_float('opt_lre',0.0001,0.1,log=True)\n",
    "    ## Memory Replay hyperparameters\n",
    "    sug_buffer_size = trial.suggest_int('buffer_size',low=100,high=1500,step=100)\n",
    "    sug_batch_size = trial.suggest_int('batch_size',low=10,high=150,step=10)\n",
    "\n",
    "    # Saving Setup\n",
    "    ## Current Parameter Values:\n",
    "    cur_n_fcl = trial.params['hidden_layers']\n",
    "    cur_fcl_size = trial.params['hidden_size']\n",
    "    cur_q_freq = trial.params['update_q_freq']\n",
    "    cur_tgt_freq = trial.params['update_tgt_freq']\n",
    "    cur_act_func = trial.params['activation_function']\n",
    "    cur_lre = decimal_to_text(trial.params['opt_lre'])\n",
    "    cur_buf_size = trial.params['buffer_size']\n",
    "    cur_bat_size = trial.params['batch_size']\n",
    "    \n",
    "    ## Create Notation for Hyperparameter Setup    \n",
    "    test_name = (f'{cur_n_fcl}FC{cur_fcl_size}_{cur_act_func}_' +\n",
    "                f'BT{cur_bat_size}BF{cur_buf_size}_Q{cur_q_freq}_' +\n",
    "                f'TGT{cur_tgt_freq}_LR{cur_lre}')\n",
    "    \n",
    "    ## Create Dir to save results\n",
    "    test_name_path =  agent_path + '/' + test_name \n",
    "    if not os.path.exists(test_name_path):\n",
    "        os.makedirs(test_name_path)\n",
    "        print(f\"Directory '{test_name_path}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{test_name_path}' already exists.\")    \n",
    "    \n",
    "    # Create Agent with hyperparameters  \n",
    "    best_ddqn_agent = DDQN(name=agent_name,\n",
    "                        environment=None,\n",
    "                        reward_function = MADDQN_return_reward,\n",
    "                        input_size= 6, \n",
    "                        hidden_size= sug_hidden_size, \n",
    "                        output_size=3, \n",
    "                        activation_function = sug_activation_function,\n",
    "                        num_hidden_layers = sug_hidden_layers,                  \n",
    "                        buffer_size= sug_buffer_size, \n",
    "                        batch_size = sug_batch_size,\n",
    "                        opt_lr= sug_opt_lre,\n",
    "                        alpha = ALPHA,\n",
    "                        gamma = GAMMA,\n",
    "                        opt_wgt_dcy = 0.0,\n",
    "                        dropout_rate = 0.25,                    \n",
    "                        device = device)\n",
    "\n",
    "    # Training Model\n",
    "    for key, env in environments.items():\n",
    "        \n",
    "        if key in trn_keys:\n",
    "            \n",
    "            best_ddqn_agent.set_environment(env)\n",
    "            best_ddqn_agent.train(start_idx=training_range[0],\n",
    "                        end_idx=training_range[1],\n",
    "                        training_epsidoes= 100,\n",
    "                        epsilon_decya_func= linear_decay,\n",
    "                        initial_epsilon= 0.9,\n",
    "                        final_epsilon= 0.1,\n",
    "                        update_q_freq= sug_update_q_freq,\n",
    "                        update_tgt_freq= sug_update_tgt_freq,\n",
    "                        save_path = export_path,\n",
    "                        val_start_idx = validation_range[0],\n",
    "                        val_end_idx = validation_range[1],\n",
    "                        early_stop = True,\n",
    "                        stop_metric = metric,\n",
    "                        stop_patience = 20,\n",
    "                        stop_delta = 0.001)\n",
    "        \n",
    "            ## Export Training Session Data to CSV\n",
    "            ddqn_trn = best_ddqn_agent.get_training_episodic_data()\n",
    "            trn_df_file_name  = f'TRN-{key}' + test_name + '.csv'\n",
    "            trn_df_save_path = test_name_path + '/' + trn_df_file_name\n",
    "            ddqn_trn.to_csv(trn_df_save_path)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Test Model\n",
    "    \n",
    "    \n",
    "    scores = []\n",
    "    for key, env in environments.items():\n",
    "    \n",
    "        if key in tst_keys:\n",
    "            \n",
    "            best_ddqn_agent.set_environment(env)              \n",
    "            best_ddqn_agent.test(start_idx = testing_range[0],\n",
    "                        end_idx = testing_range[1], \n",
    "                        testing_epsidoes=1)\n",
    "\n",
    "            ## Save Test Metric Result(s) into \n",
    "            ddqn_tst = best_ddqn_agent.get_testing_episodic_data()\n",
    "            score = ddqn_tst['Total Reward'].mean()\n",
    "            scores.append(score)\n",
    "    \n",
    "            ## Export Test data\n",
    "            a = env.get_step_data()\n",
    "            b = best_ddqn_agent.get_step_data()\n",
    "            combined_df = pd.concat([a,b],axis=1)\n",
    "            tst_df_file_name  = f'TST-{key}' + test_name + '.csv'\n",
    "            trn_df_save_path = test_name_path + '/' + tst_df_file_name\n",
    "            combined_df.to_csv(trn_df_save_path)\n",
    "\n",
    "            ## Generate Trading Graphic\n",
    "            tst_graph_file_name = trn_df_save_path[:-4] + '.png'\n",
    "            agentperform.agent_stock_performance(env.stock_price_data[testing_range[0]:testing_range[1]],\n",
    "                                                combined_df['Env Action'].to_numpy(),\n",
    "                                                key,\n",
    "                                                best_ddqn_agent.get_name(),\n",
    "                                                display_graph=True,\n",
    "                                                save_graphic=True,\n",
    "                                                path_file=tst_graph_file_name)\n",
    "\n",
    "    mean = np.mean(scores)\n",
    "    return mean\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best value: \", study.best_value)\n",
    "print(\"Best params: \", study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MADDQN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
