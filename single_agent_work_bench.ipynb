{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atpmeCKJQFm_"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAeE9oqlQFnD"
      },
      "source": [
        "## Google Colab Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C68ncf6KQFnE"
      },
      "source": [
        "### Install Python Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-8QZlwoQFnE",
        "outputId": "c93ef470-6de0-43da-f16a-7b75e1717e41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running in another environment (e.g., VS Code)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Code specific to Google Colab\n",
        "    print(\"Running in Google Colab\")\n",
        "\n",
        "    # Additional setup commands for Colab\n",
        "    !pip install neuralforecast\n",
        "    !pip install gymnasium\n",
        "    !pip install QuantStats\n",
        "    !pip install -U kaleido\n",
        "else:\n",
        "    # Code for other environments (e.g., VS Code)\n",
        "    print(\"Running in another environment (e.g., VS Code)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s8-HY3ZQFnG"
      },
      "source": [
        "### Install RL Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT3SpOINQFnH",
        "outputId": "ff9fd1b4-d9dc-471a-a5cb-0119575dec34"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    # Retrive required files\n",
        "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/environments/stockenv.py\n",
        "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/utilities/cleandata.py\n",
        "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/utilities/data.py\n",
        "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/utilities/epsilon_decay.py\n",
        "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/utilities/agentperform.py\n",
        "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/utilities/prob_evaluate.py\n",
        "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/agents/ddqn.py\n",
        "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/agents/buyhold.py\n",
        "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/agents/random.py\n",
        "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/agents/baseagent.py\n",
        "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/rewards/stockmarket.py\n",
        "    # Move all directories and files from content/raw.githubusercontent.com to content/\n",
        "    !mv /content/raw.githubusercontent.com/* /content/\n",
        "\n",
        "    # Delete the raw.githubusercontent.com directory\n",
        "    !rm -rf /content/raw.githubusercontent.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrbfXX7DQFnI"
      },
      "source": [
        "# Activate Python Libraries & Random Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKyWuV4wQFnI",
        "outputId": "324836b6-7087-48a0-d20a-823894e3aaa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA (GPU support) is not available. PyTorch is running on CPU.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import torch\n",
        "import optuna\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import utilities.agentperform as agentperform\n",
        "import utilities.cleandata as cln\n",
        "from optuna.visualization import plot_parallel_coordinate\n",
        "from utilities.epsilon_decay import linear_decay\n",
        "from utilities.data import UniStockEnvDataStruct, TimesNetProcessing, ModifyDDQNAgentState\n",
        "from utilities import prob_evaluate\n",
        "from agents.ddqn import DdqnAgent\n",
        "from agents.random import RandomAgent\n",
        "from agents.buyhold import BuyHoldAgent\n",
        "from rewards.stockmarket import future_profit, risk_reward, zero_reward\n",
        "from environments.stockenv import ContinuousOHLCVEnv\n",
        "from datetime import datetime\n",
        "from neuralforecast.core import NeuralForecast\n",
        "from neuralforecast.models import TimesNet\n",
        "from neuralforecast.losses.numpy import mae, mse\n",
        "import logging\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#\n",
        "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").addHandler(logging.NullHandler())\n",
        "logging.getLogger(\"pytorch_lightning.accelerators.cuda\").addHandler(logging.NullHandler())\n",
        "os.environ['NIXTLA_ID_AS_COL'] = '1' # Prevent Warning\n",
        "\n",
        "def set_seed(seed):\n",
        "    \"\"\"Set seed for reproducibility.\"\"\"\n",
        "    # Python random module\n",
        "    random.seed(seed)\n",
        "\n",
        "    # NumPy\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # PyTorch\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # If you are using CUDA\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "        # Additional settings to force determinism in your operations:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "\n",
        "# Check if CUDA (GPU support) is available\n",
        "if torch.cuda.is_available():\n",
        "    # Get the current device\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(device)}\")\n",
        "else:\n",
        "    device = 'cpu'\n",
        "    print(\"CUDA (GPU support) is not available. PyTorch is running on CPU.\")\n",
        "\n",
        "\n",
        "def decimal_to_text(decimal_number):\n",
        "    # Remove the decimal point and convert to integer\n",
        "    integer_part = int(decimal_number * 1000)\n",
        "    # Convert the integer to text\n",
        "    text_representation = str(integer_part)\n",
        "    return text_representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSGPXNdIQFnK"
      },
      "source": [
        "# RL Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqgSqhMDQFnK"
      },
      "source": [
        "## Parameters & CSV Locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_iIDvcGSQFnK"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 42\n",
        "set_seed(RANDOM_SEED)\n",
        "\n",
        "\n",
        "\n",
        "if not IN_COLAB:\n",
        "    pwd = \"C:/programming/MADDQN\"\n",
        "    sys.path.append(pwd)\n",
        "\n",
        "    # Output Path Location for CSV export\n",
        "    export_path = pwd + \"/output_data/test/\"\n",
        "else:\n",
        "    from google.colab import drive\n",
        "    # Connect Google Drive to download records for autoclosing of VM\n",
        "    drive.mount('/content/drive')\n",
        "    pwd = '/content'\n",
        "    export_path = pwd + \"/output_data/test/\"\n",
        "\n",
        "# Input Data Location, File Name, Stock name for labels\n",
        "input_url = 'https://raw.githubusercontent.com/CodeBeckZero/MADDQN/main/input_data'\n",
        "\n",
        "stock_inputs ={'DJI':'^DJI_daily.csv',\n",
        "               'NDAQ': '^IXIC_daily.csv',\n",
        "               'SP500': '^SPX_daily.csv',\n",
        "               'AAPL': 'AAPL_daily.csv',\n",
        "               'AMZN': 'AMZN_daily.csv',\n",
        "               'GOOGL': 'GOOGL_daily.csv',\n",
        "               'MSFT': 'MSFT_daily.csv',\n",
        "               'SINE': 'sine_wave_daily.csv',\n",
        "               'FORD': 'F_daily.csv',\n",
        "               'JNJ': 'JNJ_daily.csv',\n",
        "               'NEE': 'NEE_daily.csv',\n",
        "               'PFE': 'PFE_daily.csv',\n",
        "               'TSLA': 'TSLA_daily.csv',\n",
        "               'COKE': 'COKE_daily.csv',\n",
        "               'PG': 'PG_daily.csv'}\n",
        "\n",
        "# Training Inputs\n",
        "trn_keys = ['DJI','NDAQ','SP500']\n",
        "training_range = ('2007-01-01','2019-12-31')\n",
        "trn_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in training_range]\n",
        "\n",
        "# Validation Inputs\n",
        "validate = False\n",
        "val_keys = trn_keys\n",
        "validation_range = ('2020-01-01', '2021-12-31')\n",
        "val_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in validation_range]\n",
        "\n",
        "# Testing Inputs\n",
        "tst_keys = ['AAPL','AMZN','GOOGL','MSFT','FORD','JNJ','NEE','PFE','TSLA','COKE','PG']\n",
        "testing_range = ('2020-01-01', '2023-12-31')\n",
        "tst_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in testing_range]\n",
        "\n",
        "# Environmental Inputs\n",
        "window_size = 28 # Needs to match the size Timesnet is trained on\n",
        "price_based_on = 'close'\n",
        "columns = ['open','high','low','close','volume']\n",
        "\n",
        "\n",
        "# Metrics Interested in\n",
        "metrics = ['n_trades','trade_dur_avg','avg_trade_ror','win_percentage','cumulative_ror','sharpe','sortino','max_drawdown']\n",
        "\n",
        "# Ranking type for Metrics\n",
        "aval_metrics_rank_dic = {'n_trades':'max','n_wins': 'max' ,'n_losses':'max','win_percentage':'max','cumulative_ror':'max',\n",
        "                 'sortino':'max','max_drawdown':'min', 'sharpe':'max', 'trade_dur_avg':'max', 'trade_dur_min':'max',\n",
        "                 'trade_dur_max':'max','buy_hold':'max', 'avg_trade_ror': 'max'}\n",
        "## See agentperform.py -> results dictionary for options\n",
        "\n",
        "# Modifying enviornment state before the\n",
        "scaling_params = {'columns': columns, 'scaling_type': 'rw_col', 'scaler_func':preprocessing.StandardScaler()}\n",
        "scaling_range = (None,None)\n",
        "if not scaling_range == (None,None):\n",
        "    scale_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in scaling_range]\n",
        "\n",
        "# Add Noise\n",
        "noise_mod_params = {'add_noise': True, 'add_noise_to_cols': columns, 'noise_mean': 0, 'noise_std': 0.1}\n",
        "\n",
        "env_mod_params = scaling_params | noise_mod_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KjIdWWtQFnL"
      },
      "source": [
        "## RL Enviornment Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qDmzkFh8QFnM"
      },
      "outputs": [],
      "source": [
        "env_data = {}\n",
        "env = {}\n",
        "\n",
        "\n",
        "for stock, file in stock_inputs.items():\n",
        "    if stock in set(trn_keys + val_keys + tst_keys):\n",
        "        # Import\n",
        "        df = cln.YAHOO_csv_input(file, input_url)\n",
        "        data_dic = UniStockEnvDataStruct(df,columns,price_based_on,window_size)\n",
        "        env_data[stock] = data_dic\n",
        "        env[stock] = ContinuousOHLCVEnv(name=stock,\n",
        "                                        ohlcv_data = env_data[stock]['rw_raw_env'] ,\n",
        "                                        stock_price_data= env_data[stock]['rw_raw_price_env'],\n",
        "                                        commission_rate=0.005)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nOEPsX6QFnM"
      },
      "source": [
        "## Generating Indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "v654qbK7QFnM"
      },
      "outputs": [],
      "source": [
        "trn_idx = {}\n",
        "val_idx = {}\n",
        "tst_idx = {}\n",
        "scale_idx = {}\n",
        "\n",
        "for stock, file in stock_inputs.items():\n",
        "    if stock in set(trn_keys + val_keys + tst_keys):\n",
        "        if stock in trn_keys:\n",
        "            trn_idx[stock] = env_data[stock].gen_rw_idxs(trn_dt_range)\n",
        "        if stock in val_keys:\n",
        "            val_idx[stock] = env_data[stock].gen_rw_idxs(val_dt_range)\n",
        "        if stock in tst_keys:\n",
        "            tst_idx[stock] = env_data[stock].gen_rw_idxs(tst_dt_range)\n",
        "        if scaling_range == (None,None):\n",
        "            scale_idx[stock] = (None,None)\n",
        "        else:\n",
        "            scale_idx[stock] = env_data[stock].gen_idxs(scale_dt_range)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2RR5eb9QFnN"
      },
      "source": [
        "# Workbench Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAmGyMmuQFnN"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yibhlUW2QFnN"
      },
      "outputs": [],
      "source": [
        "## Create Directory\n",
        "case_name = '/test_unit_run02'\n",
        "save_path_root = pwd + case_name\n",
        "os.makedirs(save_path_root, exist_ok=False)\n",
        "\n",
        "# Timesnet\n",
        "## Number of price predictions in the Future by TimesNet (Required for RL agent's input layer)\n",
        "n_prediction = 5\n",
        "## Need to Train TimesNet Preprocessing model (processed every cycle)\n",
        "train_tn_model = False\n",
        "## Importing TimesNet Preprocessing model (processed every cycle)\n",
        "import_tn_model = False\n",
        "tn_model_path = pwd + '/gen_data/timesnet/'\n",
        "## Use Imported CSVs from Preprocessing model (no processing, straight to RL agent)\n",
        "import_tn_csvs = True\n",
        "tn_csvs_path = pwd + '/gen_data/csvs/'\n",
        "## No modifaction of environmental state before input to agent\n",
        "no_tn_preprocessing = False\n",
        "\n",
        "# Limited Exploratory Hyperparmater Discover for single RL Agent\n",
        "hyperparam_discovery = False\n",
        "use_best_params = False\n",
        "\n",
        "# Traditional Training/Testing\n",
        "## Train Agent(s)\n",
        "train_agent = True\n",
        "# Test Agent(s)\n",
        "test_agent = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SViA7zL9QFnN"
      },
      "outputs": [],
      "source": [
        "if  not(train_tn_model ^ import_tn_model ^ import_tn_csvs ^ no_tn_preprocessing):\n",
        "    raise ValueError(\"Only one preprocessing options can and must be selected\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU5O6X0oQFnO"
      },
      "source": [
        "## Metric Function\n",
        "\n",
        "Function that generates metric from enviornment that will be used during validation phase of training or testing phase of model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GzYRJ4-dQFnO"
      },
      "outputs": [],
      "source": [
        "def metric_function(env):\n",
        "    metric = env.step_info[-1]['New Portfolio Value'] -  env.step_info[-1]['Portfolio Value']\n",
        "    return metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1_EYhgoQFnP"
      },
      "source": [
        "# TimesNet Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7OpXBjUQFnP"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckS9XQTxQFnP"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nMjZ8cZJQFnQ"
      },
      "outputs": [],
      "source": [
        "if train_tn_model:\n",
        "\n",
        "    model = TimesNet(h = n_prediction,          # Forecast horizon\n",
        "                    input_size = window_size,   # Length of Batches\n",
        "                    batch_size = 1,             # Number of timeseries to predict\n",
        "                    #futr_exog_list = remaining_columns,\n",
        "                    hidden_size = 128,          # Size of embedding for embedding and encoders,\n",
        "                    dropout = 0.40,             # Dropout for embeddings\n",
        "                    conv_hidden_size = 3,       # Channels for the inception block\n",
        "                    top_k = 5,                  # Top num of periods from FFT considered\n",
        "                    num_kernels = 13,           # number of kernels for the inception block\n",
        "                    encoder_layers = 3,         # num of encoders\n",
        "                    max_steps = 1000,           # of training steps\n",
        "                    early_stop_patience_steps = 10, #early stoppage on validation\n",
        "                    val_check_steps = 100,      # Val check every X steps,\n",
        "                    windows_batch_size = 150,   # Number of windows in training epoch,\n",
        "                    num_workers_loader = 7,\n",
        "                    learning_rate = 0.0003,\n",
        "                    random_seed = RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKX00xoOQFnQ"
      },
      "source": [
        "### Code Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RRjzLmp2QFnR"
      },
      "outputs": [],
      "source": [
        "if train_tn_model:\n",
        "  nf = NeuralForecast(models=[model], freq='d')\n",
        "  results = {}\n",
        "  for key in trn_keys:\n",
        "    results[key] = nf.fit(df=env[key],val_size=0.2)\n",
        "\n",
        "  nf.save(path= tn_model_path,\n",
        "          model_index=None,\n",
        "          overwrite=True,\n",
        "          save_dataset=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JHWsNYIQFnR"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YCtZ140VQFnS"
      },
      "outputs": [],
      "source": [
        "if import_tn_model:\n",
        "# Define the correct path\n",
        "  if IN_COLAB:\n",
        "\n",
        "    model_path = os.path.join(os.getcwd(), 'gen_data', 'timesnet')\n",
        "\n",
        "    # Ensure the directory and file exist\n",
        "    if os.path.exists(model_path):\n",
        "        nf = NeuralForecast.load(path=model_path)\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Model path {model_path} does not exist.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI00cUAeQFnS"
      },
      "source": [
        "## CSV Upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iVuHiiPNQFnS"
      },
      "outputs": [],
      "source": [
        "if import_tn_csvs:\n",
        "    env_mod_func_dic = {}\n",
        "    if IN_COLAB:\n",
        "        # Input Data Location, File Name, Stock name for labels\n",
        "        csv_path = 'https://raw.githubusercontent.com/CodeBeckZero/MADDQN/main/gen_data/csvs/'\n",
        "\n",
        "    else:\n",
        "        csv_path  = tn_csvs_path\n",
        "\n",
        "    stock_tn ={'DJI':'DJI_tn.csv',\n",
        "                'NDAQ': 'NDAQ_tn.csv',\n",
        "                'SP500': 'SP500_tn.csv',\n",
        "                'AAPL': 'AAPL_tn.csv',\n",
        "                'AMZN': 'AMZN_tn.csv',\n",
        "                'GOOGL': 'GOOGL_tn.csv',\n",
        "                'MSFT': 'MSFT_tn.csv',\n",
        "                'FORD': 'FORD_tn.csv',\n",
        "                'JNJ': 'JNJ_tn.csv',\n",
        "                'NEE': 'NEE_tn.csv',\n",
        "                'PFE': 'PFE_tn.csv',\n",
        "                'TSLA': 'TSLA_tn.csv',\n",
        "                'COKE': 'COKE_tn.csv',\n",
        "                'PG': 'PG_tn.csv'}\n",
        "\n",
        "    for stock in set(trn_keys + val_keys + tst_keys):\n",
        "        import_csv_path = f'{csv_path}/{stock_tn[stock]}'\n",
        "        temp_env_mod_fuc = ModifyDDQNAgentState(uni_data=env_data[stock],\n",
        "                                                csv_import=import_tn_csvs,\n",
        "                                                csv_path=import_csv_path,\n",
        "                                                start_scale_idx=scale_idx[stock][0],\n",
        "                                                finish_scale_idx=scale_idx[stock][1],\n",
        "                                                **env_mod_params)\n",
        "        env_mod_func_dic[stock] = temp_env_mod_fuc\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuCCAyfQQFnT"
      },
      "source": [
        "## Direct\n",
        "Current direct default is to take the rolling windows last entry and convert it to a list prior to input to agent. Agent's experience memory is currently list-based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "13TlC9uQQFnT"
      },
      "outputs": [],
      "source": [
        "if no_tn_preprocessing:\n",
        "    env_mod_func_dic = {}\n",
        "    for stock in set(trn_keys + val_keys + tst_keys):\n",
        "        temp_env_mod_fuc = ModifyDDQNAgentState(uni_data=env_data[stock],\n",
        "                                                columns=columns,\n",
        "                                                csv_import= None,\n",
        "                                                csv_path= None,\n",
        "                                                scaling_type= None,\n",
        "                                                scaler_func=None,\n",
        "                                                device=device)\n",
        "        env_mod_func_dic[stock] = temp_env_mod_fuc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90L1szCuQFnU"
      },
      "source": [
        "# Exploratory Hyperparameterization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WVVfJu8QFnU"
      },
      "source": [
        "## Interval Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TF9AGtlpQFnV"
      },
      "outputs": [],
      "source": [
        "if hyperparam_discovery:\n",
        "    # Training Inputs\n",
        "    hyp_training_range = ('2007-01-01','2020-12-31')\n",
        "    hyp_trn_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in hyp_training_range]\n",
        "\n",
        "    # Validation Inputs\n",
        "    hyp_validate = False\n",
        "    hyp_validation_range = ('2021-01-01', '2021-12-31')\n",
        "    hyp_val_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in hyp_validation_range]\n",
        "\n",
        "    # Testing Inputs\n",
        "    hyp_testing_range = ('2021-01-01', '2023-12-31')\n",
        "    hyp_tst_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in hyp_testing_range]\n",
        "\n",
        "  # Modifying enviornment state before the\n",
        "    hyp_scaling_params = {'columns': columns, 'scaling_type': 'col', 'scaler_func':preprocessing.StandardScaler()}\n",
        "    hyp_scaling_range = ('2007-01-01','2020-12-31')\n",
        "    if not hyp_scaling_range == (None,None):\n",
        "        hyp_scale_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in scaling_range]\n",
        "    \n",
        "    # Add Noise\n",
        "    hyp_noise_mod_params = {'add_noise': True, 'add_noise_to_cols': columns, 'noise_mean': 0, 'noise_std': 0.1}\n",
        "\n",
        "    hyp_env_mod_params = hyp_scaling_params | hyp_noise_mod_params\n",
        "    \n",
        "    \n",
        "    hyp_trn_idx = {}\n",
        "    hyp_val_idx = {}\n",
        "    hyp_tst_idx = {}\n",
        "    hyp_scale_idx = {}\n",
        "\n",
        "    for stock, file in stock_inputs.items():\n",
        "        if stock in set(trn_keys + val_keys + tst_keys):\n",
        "            if stock in trn_keys:\n",
        "                hyp_trn_idx[stock] = env_data[stock].gen_rw_idxs(hyp_trn_dt_range)\n",
        "            if stock in val_keys:\n",
        "                hyp_val_idx[stock] = env_data[stock].gen_rw_idxs(hyp_val_dt_range)\n",
        "            if stock in tst_keys:\n",
        "                hyp_tst_idx[stock] = env_data[stock].gen_rw_idxs(hyp_tst_dt_range)\n",
        "            if hyp_scaling_range == (None,None):\n",
        "                hyp_scale_idx[stock] = (None,None)\n",
        "            else:\n",
        "                hyp_scale_idx[stock] = env_data[stock].gen_idxs(hyp_scale_dt_range)\n",
        "\n",
        "    display(hyp_trn_idx,hyp_val_idx,hyp_tst_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPOgs_k5QFnV"
      },
      "source": [
        "## Parameter Search & Code Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_KBlSkuFQFnW"
      },
      "outputs": [],
      "source": [
        "if hyperparam_discovery:\n",
        "\n",
        "    # For Objective function, need to create agent name before to link agent with enviornment\n",
        "    agent_name = 'hyp_profit_agent'\n",
        "    agent_path = save_path_root + '/hyp_param_search'\n",
        "    metric = 'val_tot_r'\n",
        "    max_len_buf = np.round(hyp_trn_idx['DJI'][1] - hyp_trn_idx['DJI'][0] + window_size, -2) -10 # manual input, could be error here if\n",
        "    print(f'Max Mem Length: {max_len_buf}')\n",
        "    \n",
        "    ## Activation Function Passing\n",
        "    activation_functions = {\n",
        "    'ELU': nn.ELU(),\n",
        "    'LRELUs02': nn.LeakyReLU(negative_slope=0.2),\n",
        "    'GELU': nn.GELU()}\n",
        "    \n",
        "\n",
        "    def objective(trial):\n",
        "        \n",
        "\n",
        "        # Define the hyperparameters to search over\n",
        "\n",
        "        ## NN hyperparameters\n",
        "        #sug_hidden_layers = trial.suggest_int('hidden_layers', low=1, high=3)\n",
        "        sug_hidden_size = trial.suggest_int('hidden_size', low=256, high=512, step=128)\n",
        "        sug_update_q_freq = trial.suggest_int('update_q_freq',low=1,high=5)\n",
        "        sug_update_tgt_freq = trial.suggest_int('update_tgt_freq',low=15,high=200)\n",
        "        sug_activation_function_name = trial.suggest_categorical('activation_function', list(activation_functions.keys()))\n",
        "        sug_activation_function = activation_functions[sug_activation_function_name]\n",
        "\n",
        "        \"\"\"\n",
        "        ## Reward Function Passing\n",
        "        reward_functions = {\n",
        "        'profit': future_profit(None,5),\n",
        "        'risk': risk_reward(None,5),\n",
        "        }\n",
        "        sug_reward_function_name = trial.suggest_categorical('reward_function', list(reward_functions.keys()))\n",
        "        sug_reward_function = reward_functions[sug_reward_function_name]\n",
        "        \"\"\"\n",
        "        ## Optimizer hyperparameters\n",
        "        sug_opt_lre = trial.suggest_categorical('opt_lre',[0.0001,.0001,0.01,0.1])\n",
        "        sug_gamma = trial.suggest_float('gamma',low=0.90,high=0.99,step=0.01)\n",
        "        ## Memory Replay hyperparameters\n",
        "        sug_buffer_size = trial.suggest_int('buffer_size',low=220,high=600,step=10)\n",
        "        sug_batch_size = trial.suggest_int('batch_size',low=50,high=200,step=5)\n",
        "\n",
        "        # Define Training Parameters\n",
        "        hyp_training_params = {'training_episodes': 1,\n",
        "                   'epsilon_decya_func': linear_decay,\n",
        "                   'initial_epsilon': 0.9,\n",
        "                   'final_epsilon': 0.1,\n",
        "                   'update_q_freq': sug_update_q_freq,\n",
        "                   'update_tgt_freq': sug_update_tgt_freq,                   \n",
        "                   'save_path': export_path,\n",
        "                   'metric_func': metric_function\n",
        "                   }\n",
        "\n",
        "        hyp_earlystop_params = {'min_training_episodes': 1,\n",
        "                   'early_stop': False,\n",
        "                   'stop_metric': None,\n",
        "                   'stop_patience': 2,\n",
        "                   'stop_delta': 0.001\n",
        "                    }\n",
        "        \n",
        "        \n",
        "        # Saving Setup\n",
        "        ## Current Parameter Values:\n",
        "        #cur_n_fcl = trial.params['hidden_layers']\n",
        "        cur_fcl_size = trial.params['hidden_size']\n",
        "        cur_q_freq = trial.params['update_q_freq']\n",
        "        cur_tgt_freq = trial.params['update_tgt_freq']\n",
        "        cur_act_func = trial.params['activation_function']\n",
        "        #cur_rwd_func = trial.params['reward_function']\n",
        "        cur_lre = decimal_to_text(trial.params['opt_lre'])\n",
        "        cur_buf_size = trial.params['buffer_size']\n",
        "        cur_bat_size = trial.params['batch_size']\n",
        "\n",
        "        ## Create Notation for Hyperparameter Setup\n",
        "        test_name = (f'2FC{cur_fcl_size}_{cur_act_func}_' +\n",
        "                    f'BT{cur_bat_size}BF{cur_buf_size}_Q{cur_q_freq}_' +\n",
        "                    f'TGT{cur_tgt_freq}_LR{cur_lre}')\n",
        "\n",
        "        ## Create Dir to save results\n",
        "        test_name_path =  agent_path + '/' + test_name\n",
        "        if not os.path.exists(test_name_path):\n",
        "            os.makedirs(test_name_path)\n",
        "            print(f\"Directory '{test_name_path}' created successfully.\")\n",
        "        else:\n",
        "            print(f\"Directory '{test_name_path}' already exists.\")\n",
        "\n",
        "        # Create Agent with hyperparameters\n",
        "        best_agent = DdqnAgent(name=agent_name,\n",
        "                            environment=None,\n",
        "                            reward_function = risk_reward,\n",
        "                            reward_params = {'n':5, 'lower': 15, 'upper': 90},\n",
        "                            env_state_mod_func = None,\n",
        "                            input_size= 16,\n",
        "                            hidden_size= sug_hidden_size,\n",
        "                            output_size=3,\n",
        "                            activation_function = sug_activation_function,\n",
        "                            num_hidden_layers = 2,\n",
        "                            buffer_size= sug_buffer_size,\n",
        "                            batch_size = sug_batch_size,\n",
        "                            alpha = sug_opt_lre,\n",
        "                            gamma = sug_gamma,\n",
        "                            opt_wgt_dcy = 0.01,\n",
        "                            dropout_rate = 0.20,\n",
        "                            device = device)\n",
        "\n",
        "        # Training Model\n",
        "        for key, rl_env in env.items():\n",
        "\n",
        "            if key in trn_keys:\n",
        "                rl_env.add_agent(agent_name)\n",
        "                rl_env.set_decision_agent(agent_name)\n",
        "                \n",
        "                if hyp_validate:\n",
        "                    hyp_idx_params = {'start_idx': hyp_trn_idx[key][0],\n",
        "                                'end_idx':hyp_trn_idx[key][1],\n",
        "                                'val_start_idx': hyp_val_idx[key][0],\n",
        "                                'val_end_idx': hyp_val_idx[key][1]}\n",
        "                else:\n",
        "                    hyp_idx_params ={'start_idx': hyp_trn_idx[key][0],\n",
        "                                'end_idx':hyp_trn_idx[key][1],\n",
        "                                'val_start_idx': None,\n",
        "                                'val_end_idx': None}\n",
        "                \n",
        "                hyp_combined_params = hyp_training_params | hyp_earlystop_params | hyp_idx_params\n",
        "                \n",
        "                best_agent.set_env_stat_modify_func(env_mod_func_dic[key].process)\n",
        "                best_agent.set_environment(rl_env)\n",
        "                best_agent.train(**hyp_combined_params)\n",
        "                \n",
        "                # Save Agent\n",
        "                file_root_name = f'{key}_TRN_{hyp_trn_idx[key][0]}-{hyp_trn_idx[key][1]}'\n",
        "                best_agent.export_Q_nn(test_name_path+\"/model_save\")\n",
        "\n",
        "                # Create/Export Records\n",
        "                env_data_record = rl_env.get_step_data()\n",
        "                agent_data_record = best_agent.get_step_data()\n",
        "                training_record =  pd.concat([env_data_record, agent_data_record], axis=1, join='inner')\n",
        "                training_record.to_csv(f'{test_name_path}/{file_root_name}_step_data.csv')\n",
        "                episodic_training_record = best_agent.get_training_episodic_data()\n",
        "                episodic_training_record.to_csv(f'{test_name_path}/{file_root_name}_epi_data.csv')\n",
        "                \n",
        "                \n",
        "                \n",
        "                rl_env.remove_agent(agent_name)\n",
        "\n",
        "        # Test Model\n",
        "\n",
        "        scores = []\n",
        "        for key, rl_env in env.items():\n",
        "\n",
        "            if key in tst_keys:\n",
        "                rl_env.add_agent(agent_name)\n",
        "                rl_env.set_decision_agent(agent_name)\n",
        "                \n",
        "                best_agent.set_env_stat_modify_func(env_mod_func_dic[key].process)\n",
        "                best_agent.set_environment(rl_env)\n",
        "                best_agent.test(start_idx = hyp_tst_idx[key][0],\n",
        "                            end_idx = hyp_tst_idx[key][1],\n",
        "                            metric_func= metric_function,\n",
        "                            testing_episodes=1)\n",
        "                rl_env.remove_agent(agent_name)\n",
        "\n",
        "                ## Save Test Metric Result(s) into\n",
        "                ddqn_tst = best_agent.get_testing_episodic_data()\n",
        "                score = ddqn_tst['tot_r'].mean()\n",
        "                scores.append(score)\n",
        "\n",
        "                ## Export Test data\n",
        "                a = rl_env.get_step_data()\n",
        "                b = best_agent.get_step_data()\n",
        "                combined_df = pd.concat([a,b],axis=1)\n",
        "                tst_df_file_name  = f'TST-{key}' + test_name + '.csv'\n",
        "                trn_df_save_path = test_name_path + '/' + tst_df_file_name\n",
        "                combined_df.to_csv(trn_df_save_path)\n",
        "\n",
        "                ## Generate Trading Graphic\n",
        "                tst_graph_file_name = trn_df_save_path[:-4] + '.png'\n",
        "                agentperform.agent_stock_performance(env[key].stock_price_data[hyp_tst_idx[key][0]:hyp_tst_idx[key][1]][:,-1,0], # Selecting all batches, last price of window, closing price\n",
        "                                                    combined_df['Env Action'].to_numpy(),\n",
        "                                                    key,\n",
        "                                                    best_agent.get_name(),\n",
        "                                                    display_graph=False,\n",
        "                                                    save_graphic=True,\n",
        "                                                    path_file=tst_graph_file_name)\n",
        "\n",
        "        mean = np.mean(scores)\n",
        "        return mean\n",
        "\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=2)\n",
        "    \n",
        "    \n",
        "    best_params = study.best_params\n",
        "    \n",
        "    # Export best Parameters\n",
        "    best_param_file_name = save_path_root + '/hyp_param_search/train_params.txt'\n",
        "\n",
        "    with open(best_param_file_name, 'w') as file:\n",
        "        for key, value in best_params.items():\n",
        "            file.write(f'{key}:\\t{value}')\n",
        "    \n",
        "    fig = plot_parallel_coordinate(study)\n",
        "    fig.show()\n",
        "    \n",
        "    # Save the figure as a PNG file\n",
        "    #fig.update_layout(width=1700, height=1100)\n",
        "    #fig.write_image(save_path_root + '/hyp_param_search/parallel_coordinate_plot.png')\n",
        "    \n",
        "    print(\"Best value: \", study.best_value)\n",
        "    print(\"Best params: \", study.best_params)   \n",
        "\n",
        "    best_params['activation_function'] = activation_functions[best_params['activation_function']] \n",
        "    display(best_params)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwUdEMmhQFnX"
      },
      "source": [
        "# Agent Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95MUF9R5QFnp"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OA5UDlQjQFnp"
      },
      "outputs": [],
      "source": [
        "# Agent Type Setup\n",
        "agent_classes = {#'risk_1': DdqnAgent,\n",
        "                 'profit_1': DdqnAgent,\n",
        "                 #'final': DdqnAgent,\n",
        "                 'random':RandomAgent,\n",
        "                 'buyhold':BuyHoldAgent}\n",
        "\n",
        "# Mul\n",
        "agent_setup = {#'risk_1': ['risk_1'],\n",
        "                 'profit_1': ['profit_1'],\n",
        "                 'random': ['random'],\n",
        "                 'buyhold':['buyhold']}\n",
        "                 #'final': ['profit_1', 'profit_2']}# for multi agent key is decision agent\n",
        "                 #'macro': 'macro',\n",
        "                 #'opt': ['profit', 'risk', 'macro']}\n",
        "\n",
        "agent_name_list = list(agent_classes.keys())\n",
        "\n",
        "agents_to_train = ['profit_1']\n",
        "\n",
        "import_agents = False\n",
        "\n",
        "agent_configs_to_import = {'profit_1': f'c:/Programming/MADDQN/test005/profit_1/profit_1_config.json',\n",
        "                           'profit_2': f'c:/Programming/MADDQN/test005/profit_2/profit_2_config.json'}\n",
        "\n",
        "agents_to_import = {'profit_1': f'c:/Programming/MADDQN/test005/profit_1/profit_1_model',\n",
        "                    'profit_2': f'c:/Programming/MADDQN/test005/profit_2/profit_2_model'}\n",
        "\n",
        "agent_params = {\n",
        "#    agent_name_list[0]:{\n",
        "#        'name': agent_name_list[0],\n",
        "#        'environment': None,\n",
        "#        'reward_function': risk_reward,\n",
        "#        'reward_params': {'n':5, 'lower': 15, 'upper': 90},\n",
        "#       'env_state_mod_func': None,  #Is Set in Training Loop\n",
        "#        'input_size': 16,\n",
        "#        'hidden_size': 256,\n",
        "#        'output_size':3,\n",
        "#        'activation_function': nn.ReLU(),\n",
        "#        'num_hidden_layers': 3,\n",
        "#        'buffer_size': 400,\n",
        "#       'batch_size': 100,\n",
        "#        'alpha': 0.005,\n",
        "#        'gamma':0.90,\n",
        "#        'opt_wgt_dcy': 0,\n",
        "#        'dropout_rate': 0.15,\n",
        "#        'device': device\n",
        "#    },\n",
        "    agent_name_list[0]:{\n",
        "        'name': agent_name_list[0],\n",
        "        'environment': None,\n",
        "        'reward_function': future_profit,\n",
        "        'reward_params': {'n':5, 'lower': 15, 'upper': 90},\n",
        "        'env_state_mod_func': None, #Is Set in Training Loop\n",
        "        'input_size': 16,\n",
        "        'hidden_size': 256,\n",
        "        'output_size':3,\n",
        "        'activation_function': nn.LeakyReLU(negative_slope=0.2),\n",
        "        'num_hidden_layers': 2,\n",
        "        'buffer_size': 500,\n",
        "        'batch_size': 195,\n",
        "        'alpha': 0.0001,\n",
        "        'gamma':0.91,\n",
        "        'opt_wgt_dcy': 0,\n",
        "        'dropout_rate': 0.20,\n",
        "        'device': device\n",
        "    },\n",
        "    agent_name_list[1]:{\n",
        "        'name': agent_name_list[1],\n",
        "        'environment': None,\n",
        "        'reward_function': zero_reward,\n",
        "        'reward_params': {},\n",
        "    },\n",
        "        agent_name_list[2]:{\n",
        "        'name': agent_name_list[2],\n",
        "        'environment': None,\n",
        "        'reward_function': zero_reward,\n",
        "        'reward_params': {},\n",
        "        }}\n",
        "\n",
        "if import_agents:\n",
        "    for agent, config_loc in agent_configs_to_import.items():\n",
        "        with open(config_loc, 'r') as json_file:\n",
        "            config_data = json.load(json_file)\n",
        "        agent_params[agent].update(config_data)\n",
        "        agent_params[agent].update({'device':device})   # Ensure Current Device is used for computing GPU (config)\n",
        "\n",
        "if use_best_params:\n",
        "    # Update first agent with best parameters\n",
        "    filtered_new_agent_params = {key: best_params[key] for key in agent_params[agent_name_list[0]] if key in best_params}\n",
        "    agent_params[agent_name_list[0]].update(filtered_new_agent_params)\n",
        "\n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbtjT_9IQFnq"
      },
      "source": [
        "## Agent Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5Wcjvy7-QFnq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "profit_1 initialized on cpu\n",
            "{'profit_1': {'name': 'profit_1', 'environment': None, 'reward_function': <function future_profit at 0x000002645B82DEE0>, 'reward_params': {'n': 5, 'lower': 15, 'upper': 90}, 'env_state_mod_func': None, 'input_size': 16, 'hidden_size': 256, 'output_size': 3, 'activation_function': LeakyReLU(negative_slope=0.2), 'num_hidden_layers': 2, 'buffer_size': 500, 'batch_size': 195, 'alpha': 0.0001, 'gamma': 0.91, 'opt_wgt_dcy': 0, 'dropout_rate': 0.2, 'device': 'cpu'}, 'random': {'name': 'random', 'environment': None, 'reward_function': <function zero_reward at 0x000002645B814400>, 'reward_params': {}}, 'buyhold': {'name': 'buyhold', 'environment': None, 'reward_function': <function zero_reward at 0x000002645B814400>, 'reward_params': {}}}\n"
          ]
        }
      ],
      "source": [
        "agents_dic = {}\n",
        "\n",
        "for agent_name, agent_class in agent_classes.items():\n",
        "    selected_agent = agent_class(**agent_params[agent_name])\n",
        "    agents_dic[agent_name] = selected_agent\n",
        "    if agent_name in agents_to_import.keys() and import_agents:\n",
        "        agents_dic[agent_name].import_Q_nn(agents_to_import[agent_name])\n",
        "\n",
        "print(agent_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4y7pGWBQFnq"
      },
      "source": [
        "# Training Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nswPoExzQFnr"
      },
      "outputs": [],
      "source": [
        "training_params = {'training_episodes': 2,\n",
        "                   'epsilon_decya_func': linear_decay,\n",
        "                   'initial_epsilon': 0.9,\n",
        "                   'final_epsilon': 0.1,\n",
        "                   'update_q_freq': 1,\n",
        "                   'update_tgt_freq': 98,\n",
        "                   'save_path': export_path,\n",
        "                   'metric_func': metric_function\n",
        "                   }\n",
        "\n",
        "earlystop_params = {'min_training_episodes': 1,\n",
        "                   'early_stop': False,\n",
        "                   'stop_metric': None,\n",
        "                   'stop_patience': 2,\n",
        "                   'stop_delta': 0.001\n",
        "                    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "if use_best_params:\n",
        "    # Update training params with best parameters\n",
        "    filtered_traing_params = {key: best_params[key] for key in training_params if key in best_params}\n",
        "    training_params.update(filtered_traing_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX37f6UKQFnr",
        "outputId": "d5599fb9-5897-4b14-b5fa-b806c405ed42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DJI ENV: Agent profit_1 added\n",
            "DJI ENV: Agent profit_1 assigned as decision agent\n",
            "\n",
            "profit_1: Training Initialized on DJI[0:3244]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if train_agent:\n",
        "    \n",
        "    # Export Training Parameters (Does nost handle imported parameters Q_value/Tgt_value)\n",
        "    train_param_file_name = save_path_root + '/train_params.txt'\n",
        "    with open(train_param_file_name, 'w') as file:\n",
        "        for key, value in training_params.items():\n",
        "            file.write(f'{key}:\\t\\t{value}\\n')\n",
        "    # Export Early Stop Paramters:\n",
        "    train_param_file_name = save_path_root + '/earlystop_params.txt'\n",
        "    with open(train_param_file_name, 'w') as file:\n",
        "        for key, value in training_params.items():\n",
        "            file.write(f'{key}:\\t\\t{value}\\n')   \n",
        "    # Agent Params\n",
        "    train_param_file_name = save_path_root + '/agent_params.txt'\n",
        "    with open(train_param_file_name, 'w') as file:\n",
        "        for agent in agent_params:\n",
        "            file.write(f'{agent}------\\n')\n",
        "            for key, value in agent_params[agent].items():\n",
        "                file.write(f'\\t{key}:\\t\\t{value}\\n')\n",
        "\n",
        "    # Which Agents to Train\n",
        "    filtered_agents = {\n",
        "        decision_agent: agents_in_setup\n",
        "        for decision_agent, agents_in_setup in agent_setup.items()\n",
        "        if decision_agent in agents_to_train\n",
        "    }\n",
        "\n",
        "    for decision_agent, agents_in_setup in filtered_agents.items():\n",
        "        for key in trn_keys:\n",
        "            rl_env = env[key]\n",
        "\n",
        "            if validate:\n",
        "                idx_params = {'start_idx': trn_idx[key][0],\n",
        "                              'end_idx':trn_idx[key][1],\n",
        "                              'val_start_idx': val_idx[key][0],\n",
        "                              'val_end_idx': val_idx[key][1]}\n",
        "            else:\n",
        "                idx_params ={'start_idx': trn_idx[key][0],\n",
        "                             'end_idx':trn_idx[key][1],\n",
        "                             'val_start_idx': None,\n",
        "                             'val_end_idx': None}\n",
        "\n",
        "            combined_params = training_params | earlystop_params | idx_params\n",
        "\n",
        "            # Setup agents with environment\n",
        "            rl_env.add_agent(decision_agent)\n",
        "            rl_env.set_decision_agent(decision_agent)   \n",
        "            agents_dic[decision_agent].set_environment(rl_env)\n",
        "\n",
        "            # Multi-Agent Setup\n",
        "            if decision_agent not in agents_in_setup or len(agents_in_setup) != 1:\n",
        "                subagent_list = []\n",
        "                for agent in agents_in_setup:\n",
        "                    subagent_list.append(agents_dic[agent])\n",
        "                env_mod_func_dic[key].add_subagents(subagent_list)\n",
        "            \n",
        "            #Train Agent    \n",
        "            agents_dic[decision_agent].set_env_stat_modify_func(env_mod_func_dic[key].process)\n",
        "            agents_dic[decision_agent].train(**combined_params)\n",
        "            \n",
        "            # Remove Multi-Agent Setup in ENV_MOD function\n",
        "            if decision_agent not in agents_in_setup or len(agents_in_setup) != 1:\n",
        "                env_mod_func_dic[key].remove_subagents()\n",
        "\n",
        "            # Save Agent\n",
        "            save_agent_path = save_path_root + f'/{decision_agent}/'\n",
        "            os.makedirs(save_agent_path, exist_ok=True)\n",
        "            file_root_name = f'{key}_TRN_{trn_idx[key][0]}-{trn_idx[key][1]}'\n",
        "            agents_dic[decision_agent].export_Q_nn(f'{save_agent_path}{decision_agent}_model')\n",
        "            agents_dic[decision_agent].save_config(f'{save_agent_path}{decision_agent}_config.json')\n",
        "            \n",
        "            # Create/Export Records\n",
        "            env_data_record = rl_env.get_step_data()\n",
        "            agent_data_record = agents_dic[decision_agent].get_step_data()\n",
        "            training_record =  pd.concat([env_data_record, agent_data_record], axis=1, join='inner')\n",
        "            training_record.to_csv(f'{save_agent_path}{file_root_name}_step_data.csv')\n",
        "            episodic_training_record = agents_dic[decision_agent].get_training_episodic_data()\n",
        "            episodic_training_record.to_csv(f'{save_agent_path}{file_root_name}_epi_data.csv')\n",
        "\n",
        "            # Remove Agent\n",
        "            rl_env.remove_agent(decision_agent)\n",
        "            agents_dic[decision_agent].set_environment(None)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVcrJ5qVQFns"
      },
      "source": [
        "# Agent Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc6ZYhOsQFns"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qegyTiiIQFns"
      },
      "outputs": [],
      "source": [
        "testing_params = {DdqnAgent: {\n",
        "                   'metric_func': metric_function,\n",
        "                   'metric_func_arg': {},\n",
        "                   'testing_episodes':1},\n",
        "                  RandomAgent: {\n",
        "                    'metric_func': metric_function,\n",
        "                   'metric_func_arg': {},\n",
        "                   'testing_episodes':5},\n",
        "                  BuyHoldAgent: {\n",
        "                    'metric_func': metric_function,\n",
        "                   'metric_func_arg': {},\n",
        "                   'testing_episodes':1}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rF1E25JQFns"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8buSLH7yQFnt"
      },
      "outputs": [],
      "source": [
        "if test_agent:\n",
        "    result_dic_struct = ['stock','agent','test_interval','test_num']\n",
        "    results = {}\n",
        "\n",
        "    for key in tst_keys:\n",
        "\n",
        "        # Init Record[Stock]\n",
        "        results[key] = {}\n",
        "        test_key = f'{tst_idx[key][0]}:{tst_idx[key][1]}'\n",
        "        stock_price_data = env_data[key]['rw_raw_price_env'][tst_idx[key][0]:tst_idx[key][1],-1,0]\n",
        "        rl_env = env[key]\n",
        "\n",
        "        for decision_agent, agents_in_setup in agent_setup.items():\n",
        "            \n",
        "            # Init Record[Stock][Agent]\n",
        "            results[key][decision_agent] = {}\n",
        "\n",
        "            # Init Record[Stock][Agent][test_interval]\n",
        "            results[key][decision_agent][test_key] = {}   # Different Test Keys will need loop\n",
        "\n",
        "            # Setup agents with environment\n",
        "            rl_env.add_agent(decision_agent)\n",
        "            rl_env.set_decision_agent(decision_agent)   \n",
        "            agents_dic[decision_agent].set_environment(rl_env)\n",
        "\n",
        "            # Enable Randomess if Agent is of class RandomAgent\n",
        "            if isinstance(agents_dic[decision_agent], RandomAgent):\n",
        "                new_random_seed = random.randint(1, 10**9)\n",
        "                set_seed(new_random_seed)\n",
        "\n",
        "            # Save Agent\n",
        "            save_agent_path = save_path_root + f'/{decision_agent}/'\n",
        "            os.makedirs(save_agent_path, exist_ok=True)\n",
        "            file_root_name = f'{key}_TST_{tst_idx[key][0]}-{tst_idx[key][1]}'\n",
        "\n",
        "            # Multi-Agent Setup\n",
        "            if decision_agent not in agents_in_setup or len(agents_in_setup) != 1:\n",
        "                print('here')\n",
        "                subagent_list = []\n",
        "                for agent in agents_in_setup:\n",
        "                    subagent_list.append(agents_dic[agent])\n",
        "                env_mod_func_dic[key].add_subagents(subagent_list)\n",
        "            \n",
        "            \n",
        "            # Test Decision Agent\n",
        "            params = testing_params[agent_classes[decision_agent]]\n",
        "            if not isinstance(agents_dic[decision_agent], (RandomAgent, BuyHoldAgent)):\n",
        "                agents_dic[decision_agent].set_env_stat_modify_func(env_mod_func_dic[key].process)\n",
        "            agents_dic[decision_agent].test(start_idx=tst_idx[key][0],\n",
        "                                            end_idx=tst_idx[key][1],\n",
        "                                            **params)\n",
        "            \n",
        "            # Remove Multi-Agent Setup in ENV_MOD function\n",
        "            if decision_agent not in agents_in_setup or len(agents_in_setup) != 1:\n",
        "                env_mod_func_dic[key].remove_subagents()\n",
        "\n",
        "            # Generate Testing Records\n",
        "            env_data_record = rl_env.get_step_data()\n",
        "            agent_data_record = agents_dic[decision_agent].get_step_data()\n",
        "            test_record =  pd.concat([env_data_record, agent_data_record], axis=1, join='inner')\n",
        "            test_record.to_csv(f'{save_agent_path}{file_root_name}_step_data.csv')\n",
        "            episodic_testing_record = agents_dic[decision_agent].get_testing_episodic_data()\n",
        "            episodic_testing_record.to_csv(f'{save_agent_path}{file_root_name}_epi_data.csv')\n",
        "\n",
        "            trade_actions_per_test = episodic_testing_record['tst_actions']\n",
        "\n",
        "            for idx, action_set in enumerate(trade_actions_per_test):\n",
        "                file_root_name = f'{key}_TST_{tst_idx[key][0]}-{tst_idx[key][1]}_{[idx]}'\n",
        "                test_metrics = agentperform.agent_stock_performance(stock_price_ts=np.array(stock_price_data),\n",
        "                                                                    trade_ts=np.array(action_set),\n",
        "                                                                    stock_name=key,\n",
        "                                                                    agent_name=decision_agent,\n",
        "                                                                    display_graph=False,\n",
        "                                                                    save_graphic= True,\n",
        "                                                                    path_file = f'{save_agent_path}{file_root_name}.png')\n",
        "                del test_metrics['stock']\n",
        "                del test_metrics['agent_name']\n",
        "                results[key][decision_agent][test_key][idx] = test_metrics\n",
        "\n",
        "            # Remove Agent\n",
        "            for agent in set([decision_agent] + agents_in_setup):\n",
        "                rl_env.remove_agent(agent)\n",
        "                agents_dic[agent].set_environment(None)\n",
        "\n",
        "    display(results)\n",
        "    set_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFAgjjt1QFnt"
      },
      "source": [
        "# Aggreating Test Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BApRg8hXQFnt"
      },
      "outputs": [],
      "source": [
        "if test_agent:\n",
        "    aggerate_results = {}\n",
        "    for agent in agent_name_list:\n",
        "        aggerate_results[agent] = {}\n",
        "        for stock in tst_keys:\n",
        "            aggerate_results[agent][stock] = {}\n",
        "            test_key = f'{tst_idx[stock][0]}:{tst_idx[stock][1]}'\n",
        "            aggerate_results[agent][stock][test_key] = {}\n",
        "            values = np.empty((0,len(metrics)))\n",
        "            for test_num in range(testing_params[agent_classes[agent]]['testing_episodes']):\n",
        "\n",
        "                values_array = [results[stock][agent][test_key][test_num][key] for key in metrics]\n",
        "                current_values = np.array(values_array)\n",
        "                values = np.vstack((values,current_values))\n",
        "\n",
        "                means_for_metrics = np.mean(values, axis=0)\n",
        "                std_for_metrics = np.std(values, axis=0)\n",
        "\n",
        "            for idx,metric in enumerate(metrics):\n",
        "                aggerate_results[agent][stock][test_key][metric] = (means_for_metrics[idx],std_for_metrics[idx])\n",
        "\n",
        "    summarized_aggerate_results = {}\n",
        "\n",
        "    for metric in metrics:\n",
        "        model_list = []\n",
        "        dataset_name = []\n",
        "        scores = []\n",
        "        for agent in aggerate_results.keys():\n",
        "\n",
        "            model_list.append(agent)\n",
        "            score_list = []\n",
        "            for stock in aggerate_results[agent].keys():\n",
        "                for test in aggerate_results[agent][stock].keys():\n",
        "                    run_name = stock + \"-\" + test\n",
        "                    if run_name not in dataset_name:\n",
        "                        dataset_name.append(run_name)\n",
        "                    score = aggerate_results[agent][stock][test][metric][0]\n",
        "                    score_list.append(np.round(score,2))\n",
        "            scores.append(score_list)\n",
        "\n",
        "        score_array = np.array(scores).T\n",
        "\n",
        "        df = pd.DataFrame(score_array,columns=model_list)\n",
        "        df['dataset'] = dataset_name\n",
        "\n",
        "        column_order = ['dataset'] + [col for col in df.columns if col != 'dataset']\n",
        "        df = df[column_order]\n",
        "        summarized_aggerate_results[metric] = df\n",
        "\n",
        "\n",
        "        # Export Aggreate Date to CSV\n",
        "        means = df[model_list].mean()\n",
        "        model_means = {model: means[model] for model in model_list}\n",
        "        model_means.update({'dataset': 'mean'})\n",
        "        df_export = df.copy()\n",
        "        df_export.loc[len(df)] = model_means\n",
        "        df_export.to_csv(f'{save_path_root}/{metric}_agg_data.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    display(summarized_aggerate_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0ZPtDYFQFnu"
      },
      "source": [
        "# Significance Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDyd0N45QFnu"
      },
      "outputs": [],
      "source": [
        "if test_agent:\n",
        "    for metric in metrics:\n",
        "        display(metric)\n",
        "        display(summarized_aggerate_results[metric])\n",
        "        test = prob_evaluate.generate_rank_array_from_dataframe(summarized_aggerate_results[metric],\n",
        "                                                                model_list,equal_rank_behav=\"mean\",\n",
        "                                                                rank_order=aval_metrics_rank_dic[metric])\n",
        "        display(test)\n",
        "        stat, critical_f_value, reject_null_hypo, k, n, pvalue = prob_evaluate.iman_davenport_test(test,0.95,arr_order='rows')\n",
        "        display(f'n models: {k}, n_datasets {n}, ImanDavenport Stat: {stat}, Critical Value: {critical_f_value}, pvalue: {pvalue}, Reject Null Hypoth: {reject_null_hypo}')\n",
        "\n",
        "        # Create a dictionary with the output values\n",
        "        result_dict = {\n",
        "                    'n_models': [k],\n",
        "                    'n_datasets': [n],\n",
        "                    'Iman_Davenport_Stat': [stat],\n",
        "                    'Critical_Value': [critical_f_value],\n",
        "                    'pvalue': [pvalue],\n",
        "                    'Reject_Null_Hypothesis': [reject_null_hypo]}\n",
        "\n",
        "        result_df = pd.DataFrame(result_dict)\n",
        "        result_df.to_csv(f'{save_path_root}/{metric}_iman_davenport_test.csv')\n",
        "\n",
        "        # Nemenyi Test\n",
        "        results_raw = prob_evaluate.nemenyi_test(test,0.95,model_list)\n",
        "        # Formating Output\n",
        "        df_export = pd.DataFrame(results_raw, columns=['agent1_agent2', 'nemenyi_stat', 'nemenyi_threshold', 'reject_null_hypo'])\n",
        "        df_export[['agent1', 'agent2']] = pd.DataFrame(df_export['agent1_agent2'].tolist(), index=df_export.index)\n",
        "        df_export = df_export.drop(columns=['agent1_agent2'])\n",
        "        new_column_order = ['agent1', 'agent2', 'nemenyi_stat', 'nemenyi_threshold', 'reject_null_hypo']\n",
        "        df_export = df_export[new_column_order]\n",
        "        df_export.to_csv(f'{save_path_root}/{metric}_nemenyi_test.csv')\n",
        "\n",
        "        display(df_export)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAx4C23NWsie"
      },
      "source": [
        "#Move records to Google Drive for VM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AVXuuyVUJtT"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "  import shutil\n",
        "  from google.colab import drive\n",
        "\n",
        "  # Connect Google Drive to download records for autoclosing of VM\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  # Define your directory path and case name\n",
        "  directory_path = save_path_root\n",
        "  zip_file_name = case_name.replace(\"/\", \"\")\n",
        "  output_filename = f'{zip_file_name}.zip'\n",
        "\n",
        "  # Create a zip file of the directory\n",
        "  shutil.make_archive(zip_file_name, 'zip', directory_path)\n",
        "\n",
        "  # Move the zip file to Google Drive\n",
        "  shutil.move(f'{zip_file_name}.zip', f'/content/drive/My Drive/{output_filename}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2THhlh2QFnv"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "90L1szCuQFnU"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
