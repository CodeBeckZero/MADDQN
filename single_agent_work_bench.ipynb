{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workbench Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in another environment (e.g., VS Code)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Code specific to Google Colab\n",
    "    print(\"Running in Google Colab\")\n",
    "\n",
    "    # Additional setup commands for Colab\n",
    "    !pip install neuralforecast\n",
    "    !pip install gymnasium\n",
    "else:\n",
    "    # Code for other environments (e.g., VS Code)\n",
    "    print(\"Running in another environment (e.g., VS Code)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # Retrive required files\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/environments/stockenv.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/utilities/cleandata.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/utilities/data.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/utilities/epsilon_decay.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/utilities/agentperform.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/agent/ddqn.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/agent/random.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/reward/stockmarket.py            \n",
    "    # Move all directories and files from content/raw.githubusercontent.com to content/\n",
    "    !mv /content/raw.githubusercontent.com/* /content/\n",
    "\n",
    "    # Delete the raw.githubusercontent.com directory\n",
    "    !rm -rf /content/raw.githubusercontent.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software Enviornment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU support) is not available. PyTorch is running on CPU.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import optuna\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import utilities.agentperform as agentperform\n",
    "import utilities.cleandata as cln \n",
    "from utilities.epsilon_decay import linear_decay\n",
    "from utilities.data import UniStockEnvDataStruct, TimesNetProcessing\n",
    "from agents.ddqn import DdqnAgent\n",
    "from rewards.stockmarket import future_profit, risk_reward\n",
    "from environments.stockenv import ContinuousOHLCVEnv\n",
    "from datetime import datetime\n",
    "import logging\n",
    "# \n",
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").addHandler(logging.NullHandler())\n",
    "logging.getLogger(\"pytorch_lightning.accelerators.cuda\").addHandler(logging.NullHandler())\n",
    "os.environ['NIXTLA_ID_AS_COL'] = '1' # Prevent Warning \n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    # Python random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # If you are using CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "        # Additional settings to force determinism in your operations:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device\n",
    "    device = torch.cuda.current_device()\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"CUDA (GPU support) is not available. PyTorch is running on CPU.\")\n",
    "\n",
    "\n",
    "def decimal_to_text(decimal_number):\n",
    "    # Remove the decimal point and convert to integer\n",
    "    integer_part = int(decimal_number * 1000)\n",
    "    # Convert the integer to text\n",
    "    text_representation = str(integer_part)\n",
    "    return text_representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "if not IN_COLAB:\n",
    "    pwd = \"C:/programming/MADDQN\"\n",
    "    sys.path.append(pwd)\n",
    "    \n",
    "    # Output Path Location for CSV export\n",
    "    export_path = pwd + \"/output_data\"\n",
    "\n",
    "# Input Data Location, File Name, Stock name for labels\n",
    "input_url = 'https://raw.githubusercontent.com/CodeBeckZero/MADDQN/main/input_data'\n",
    "\n",
    "stock_inputs ={'DJI':'^DJI_daily.csv',\n",
    "               'NDAQ': '^IXIC_daily.csv',\n",
    "               'SP500': '^SPX_daily.csv',\n",
    "               'AAPL': 'AAPL_daily.csv',\n",
    "               'AMZN': 'AMZN_daily.csv',\n",
    "               'GOOGL': 'GOOGL_daily.csv',\n",
    "               'MSFT': 'MSFT_daily.csv',\n",
    "               'SINE': 'sine_wave_daily.csv',\n",
    "               'FORD': 'F_daily.csv',\n",
    "               'JNJ': 'JNJ_daily.csv',\n",
    "               'NEE': 'NEE_daily.csv',\n",
    "               'PFE': 'PFE_daily.csv',\n",
    "               'TSLA': 'TSLA_daily.csv',\n",
    "               'COKE': 'COKE_daily.csv',\n",
    "               'PG': 'PG_daily.csv'}\n",
    "\n",
    "# Training Inputs\n",
    "trn_keys = ['DJI']#,'NDAQ','SP500']\n",
    "training_range = ('2007-01-01','2019-12-31')\n",
    "trn_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in training_range]\n",
    "\n",
    "# Validation Inputs\n",
    "val_keys = trn_keys\n",
    "validation_range = ('2021-01-01', '2022-12-31')\n",
    "val_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in validation_range]\n",
    "\n",
    "# Testing Inputs\n",
    "tst_keys = trn_keys#['AAPL','AMAZON','GOOGL','MSFT','FORD','JNJ','NEE','PFE','TSLA','COKE','PG']\n",
    "testing_range = ('2021-01-01', '2022-12-31')\n",
    "tst_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in testing_range]\n",
    "\n",
    "window_size = 28 # Needs to match the size Timesnet is trained on\n",
    "price_based_on = 'close'\n",
    "columns = ['open','high','low','close','volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Enviornment Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "env_data = {}\n",
    "env = {}\n",
    "\n",
    "for stock, file in stock_inputs.items():\n",
    "    if stock in set(trn_keys + val_keys + tst_keys):\n",
    "        # Import\n",
    "        df = cln.YAHOO_csv_input(file, input_url)\n",
    "        data_dic = UniStockEnvDataStruct(df,price_based_on,window_size)\n",
    "        env_data[stock] = data_dic\n",
    "        env[stock] = ContinuousOHLCVEnv(name=stock,\n",
    "                                        ohlcv_data = env_data[stock]['rw_raw_env'] ,\n",
    "                                        stock_price_data= env_data[stock]['rw_raw_price_env'],\n",
    "                                        commission_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2007, 1, 1, 0, 0), datetime.datetime(2019, 12, 31, 0, 0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'DJI': (0, 3244)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2022, 12, 31, 0, 0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'DJI': (3525, 4000)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2022, 12, 31, 0, 0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'DJI': (3525, 4000)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trn_idx = {}\n",
    "val_idx = {}\n",
    "tst_idx = {}\n",
    "\n",
    "for stock, file in stock_inputs.items():\n",
    "    if stock in set(trn_keys + val_keys + tst_keys):\n",
    "        if stock in trn_keys:\n",
    "            trn_idx[stock] = env_data[stock].gen_rw_idxs(trn_dt_range)\n",
    "        if stock in val_keys:\n",
    "            val_idx[stock] = env_data[stock].gen_rw_idxs(val_dt_range)\n",
    "        if stock in tst_keys:\n",
    "            tst_idx[stock] = env_data[stock].gen_rw_idxs(tst_dt_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timesnet Preprocessing Module (Option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "tn_path = pwd + '/gen_data/timesnet/'\n",
    "timesnet = TimesNetProcessing(env_data,tn_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CSV export from Timesnet Preprocessing Model (Option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    # Input Data Location, File Name, Stock name for labels\n",
    "    csv_path = 'https://raw.githubusercontent.com/CodeBeckZero/MADDQN/main/input_data'\n",
    "else:\n",
    "\n",
    "    csv_path  = pwd +'/gen_data/csvs/'\n",
    "\n",
    "stock_tn ={'DJI':'DJI_tn.csv',\n",
    "               'NDAQ': 'NDAQ_tn.csv',\n",
    "               'SP500': 'SP500_tn.csv',\n",
    "               'AAPL': 'AAPL_tn.csv',\n",
    "               'AMZN': 'AMZN_tn.csv',\n",
    "               'GOOGL': 'GOOGL_tn.csv',\n",
    "               'MSFT': 'MSFT_tn.csv',\n",
    "               'FORD': 'FORD_tn.csv',\n",
    "               'JNJ': 'JNJ_tn.csv',\n",
    "               'NEE': 'NEE_tn.csv',\n",
    "               'PFE': 'PFE_tn.csv',\n",
    "               'TSLA': 'TSLA_tn.csv',\n",
    "               'COKE': 'COKE_tn.csv',\n",
    "               'PG': 'PG_tn.csv'}\n",
    "\n",
    "timesnet = TimesNetProcessing(env_data,tn_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDQN Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ddqn_agent = DdqnAgent(name='profit',\n",
    "                        environment=None,\n",
    "                        reward_function = future_profit,\n",
    "                        reward_params = {'n':5},\n",
    "                        env_state_mod_func = timesnet.csv_process,     \n",
    "                        input_size= 11,\n",
    "                        hidden_size= 256, \n",
    "                        output_size=3, \n",
    "                        activation_function = nn.ReLU(),\n",
    "                        num_hidden_layers = 2,                  \n",
    "                        buffer_size= 100, \n",
    "                        batch_size = 20,\n",
    "                        opt_lr= 0,\n",
    "                        alpha = 0.001,\n",
    "                        gamma = 0.9,\n",
    "                        opt_wgt_dcy = 0.0,\n",
    "                        dropout_rate = 0.25,                \n",
    "                        device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train DDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DJI ENV: Agent profit added\n",
      "DJI ENV: Agent profit assigned as decision agent\n",
      "profit: Training Initialized on DJI[0:3244] -> Validation on DJI[3525:4000]\n",
      "profit: EP 16 of 100 Finished -> ΔQ1 = 0.11, ΔQ2 = 0.04 | ∑R = 151.97, μR = 0.05 σR = 1.64                                                                                                              "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m env[key]\u001b[38;5;241m.\u001b[39mset_decision_agent(best_ddqn_agent\u001b[38;5;241m.\u001b[39mget_name())\n\u001b[0;32m      7\u001b[0m best_ddqn_agent\u001b[38;5;241m.\u001b[39mset_environment(rl_env)\n\u001b[1;32m----> 8\u001b[0m best_ddqn_agent\u001b[38;5;241m.\u001b[39mtrain(start_idx \u001b[38;5;241m=\u001b[39m trn_idx[key][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m      9\u001b[0m             end_idx\u001b[38;5;241m=\u001b[39mtrn_idx[key][\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     10\u001b[0m             training_episodes\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     11\u001b[0m             epsilon_decya_func\u001b[38;5;241m=\u001b[39m linear_decay,\n\u001b[0;32m     12\u001b[0m             initial_epsilon\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m,\n\u001b[0;32m     13\u001b[0m             final_epsilon\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     14\u001b[0m             update_q_freq\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     15\u001b[0m             update_tgt_freq\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     16\u001b[0m             save_path \u001b[38;5;241m=\u001b[39m export_path,\n\u001b[0;32m     17\u001b[0m             val_start_idx \u001b[38;5;241m=\u001b[39m val_idx[key][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     18\u001b[0m             val_end_idx \u001b[38;5;241m=\u001b[39m val_idx[key][\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     19\u001b[0m             early_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     20\u001b[0m             stop_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_ror\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m             stop_patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     22\u001b[0m             stop_delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m## Export Training Session Data to CSV\u001b[39;00m\n\u001b[0;32m     25\u001b[0m ddqn_trn \u001b[38;5;241m=\u001b[39m best_ddqn_agent\u001b[38;5;241m.\u001b[39mget_training_episodic_data()\n",
      "File \u001b[1;32mc:\\Programming\\MADDQN\\agents\\ddqn.py:248\u001b[0m, in \u001b[0;36mDdqnAgent.train\u001b[1;34m(self, start_idx, end_idx, training_episodes, epsilon_decya_func, initial_epsilon, final_epsilon, val_start_idx, val_end_idx, save_path, early_stop, stop_metric, stop_patience, stop_delta, update_q_freq, update_tgt_freq)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, training_episodes\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    243\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m epsilon_decya_func(initial_epsilon, \n\u001b[0;32m    244\u001b[0m                                     final_epsilon,\n\u001b[0;32m    245\u001b[0m                                     episode_num,\n\u001b[0;32m    246\u001b[0m                                     training_episodes)\n\u001b[1;32m--> 248\u001b[0m     tot_reward, mean_reward, std_reward, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_play_episode(epsilon, update_q_freq, update_tgt_freq, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;66;03m# Rewards based on Validation Set\u001b[39;00m\n\u001b[0;32m    250\u001b[0m     val_tot_reward, val_avg_reward, val_std_reward, _, ror, cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(val_start_idx,val_end_idx)\n",
      "File \u001b[1;32mc:\\Programming\\MADDQN\\agents\\ddqn.py:332\u001b[0m, in \u001b[0;36mDdqnAgent._play_episode\u001b[1;34m(self, epsilon, update_q_freq, update_tgt_freq, step_type)\u001b[0m\n\u001b[0;32m    327\u001b[0m     _ , action, reward, _ , end , action_type, q_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_act(\u001b[38;5;241m0\u001b[39m, step_type)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m step_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m:    \n\u001b[0;32m    330\u001b[0m     \n\u001b[0;32m    331\u001b[0m     \u001b[38;5;66;03m# Act On Ev\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m     state, action, reward, new_state, end, action_type, q_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_act(epsilon, step_type)\n\u001b[0;32m    333\u001b[0m     exp \u001b[38;5;241m=\u001b[39m Experience(state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_act_env_to_nn[action], reward,end, new_state)\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_memory\u001b[38;5;241m.\u001b[39mappend(exp)\n",
      "File \u001b[1;32mc:\\Programming\\MADDQN\\agents\\ddqn.py:424\u001b[0m, in \u001b[0;36mDdqnAgent._act\u001b[1;34m(self, epsilon, step_type)\u001b[0m\n\u001b[0;32m    422\u001b[0m     action_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplore\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 424\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_act_nn_to_env[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_action(state, step_type)]\n\u001b[0;32m    425\u001b[0m     action_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;66;03m# Record all value of current state and action\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programming\\MADDQN\\agents\\ddqn.py:440\u001b[0m, in \u001b[0;36mDdqnAgent._best_action\u001b[1;34m(self, state, step_type)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_best_action\u001b[39m(\u001b[38;5;28mself\u001b[39m,state,step_type):\n\u001b[1;32m--> 440\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ1_nn(torch\u001b[38;5;241m.\u001b[39mtensor(state,dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;66;03m# Q-values are only attached for Gradient calc during mini-batch training\u001b[39;00m\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (step_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_memory\u001b[38;5;241m.\u001b[39mis_full()):\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programming\\MADDQN\\agents\\ddqn.py:580\u001b[0m, in \u001b[0;36mQ_Network.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;66;03m# Forward pass through the network\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ_nn(x)\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for key, rl_env in env.items():\n",
    "    \n",
    "    if key in trn_keys:\n",
    "        timesnet.upload_csv(csv_path + stock_tn[key])\n",
    "        env[key].add_agent(best_ddqn_agent.get_name())\n",
    "        env[key].set_decision_agent(best_ddqn_agent.get_name())\n",
    "        best_ddqn_agent.set_environment(rl_env)\n",
    "        best_ddqn_agent.train(start_idx = trn_idx[key][0],\n",
    "                    end_idx=trn_idx[key][1],\n",
    "                    training_episodes= 100,\n",
    "                    epsilon_decya_func= linear_decay,\n",
    "                    initial_epsilon= 0.9,\n",
    "                    final_epsilon= 0.1,\n",
    "                    update_q_freq= 1,\n",
    "                    update_tgt_freq= 10,\n",
    "                    save_path = export_path,\n",
    "                    val_start_idx = val_idx[key][0],\n",
    "                    val_end_idx = val_idx[key][1],\n",
    "                    early_stop = False,\n",
    "                    stop_metric = 'val_ror',\n",
    "                    stop_patience = 20,\n",
    "                    stop_delta = 0.001)\n",
    "    \n",
    "        ## Export Training Session Data to CSV\n",
    "        ddqn_trn = best_ddqn_agent.get_training_episodic_data()\n",
    "        ddqn_trn.to_csv('test.csv')\n",
    "        display(ddqn_trn)\n",
    "        env[key].remove_agent(best_ddqn_agent.get_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>idx</th>\n",
       "      <th>Portfolio Value</th>\n",
       "      <th>Cash</th>\n",
       "      <th>Stock Value</th>\n",
       "      <th>Stock Holdings</th>\n",
       "      <th>Stock Price</th>\n",
       "      <th>State</th>\n",
       "      <th>Available Actions</th>\n",
       "      <th>Env Action</th>\n",
       "      <th>New Portfolio Value</th>\n",
       "      <th>New Cash</th>\n",
       "      <th>New Stock Value</th>\n",
       "      <th>New Stock Holdings</th>\n",
       "      <th>New Commission Cost</th>\n",
       "      <th>Total Commission Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>13424.39</td>\n",
       "      <td>([[13062.75, 13137.76, 13041.3, 13136.14, 2489...</td>\n",
       "      <td>(H, B)</td>\n",
       "      <td>B</td>\n",
       "      <td>99530.14635</td>\n",
       "      <td>5559.41635</td>\n",
       "      <td>93970.73</td>\n",
       "      <td>7</td>\n",
       "      <td>469.85365</td>\n",
       "      <td>469.85365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>99530.14635</td>\n",
       "      <td>5559.41635</td>\n",
       "      <td>93974.72</td>\n",
       "      <td>7</td>\n",
       "      <td>13424.96</td>\n",
       "      <td>([[13133.94, 13256.33, 13130.53, 13211.88, 251...</td>\n",
       "      <td>(S, H)</td>\n",
       "      <td>S</td>\n",
       "      <td>99064.26275</td>\n",
       "      <td>99064.26275</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>469.87360</td>\n",
       "      <td>939.72725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>99064.26275</td>\n",
       "      <td>99064.26275</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>13295.01</td>\n",
       "      <td>([[13206.65, 13246.82, 13196.03, 13241.38, 247...</td>\n",
       "      <td>(H, B)</td>\n",
       "      <td>B</td>\n",
       "      <td>98598.93740</td>\n",
       "      <td>5533.86740</td>\n",
       "      <td>93065.07</td>\n",
       "      <td>7</td>\n",
       "      <td>465.32535</td>\n",
       "      <td>1405.05260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>98598.93740</td>\n",
       "      <td>5533.86740</td>\n",
       "      <td>94376.45</td>\n",
       "      <td>7</td>\n",
       "      <td>13482.35</td>\n",
       "      <td>([[13243.08, 13284.53, 13228.78, 13264.62, 236...</td>\n",
       "      <td>(S, H)</td>\n",
       "      <td>S</td>\n",
       "      <td>99438.43515</td>\n",
       "      <td>99438.43515</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>471.88225</td>\n",
       "      <td>1876.93485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>99438.43515</td>\n",
       "      <td>99438.43515</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>13553.73</td>\n",
       "      <td>([[13264.13, 13317.69, 13260.8, 13312.97, 2061...</td>\n",
       "      <td>(H, B)</td>\n",
       "      <td>B</td>\n",
       "      <td>98964.05460</td>\n",
       "      <td>4087.94460</td>\n",
       "      <td>94876.11</td>\n",
       "      <td>7</td>\n",
       "      <td>474.38055</td>\n",
       "      <td>2351.31540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>228</td>\n",
       "      <td>308</td>\n",
       "      <td>35487.90405</td>\n",
       "      <td>35487.90405</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>13058.20</td>\n",
       "      <td>([[12531.79, 12531.95, 12376.7, 12422.86, 2350...</td>\n",
       "      <td>(H, B)</td>\n",
       "      <td>B</td>\n",
       "      <td>35357.32205</td>\n",
       "      <td>9240.92205</td>\n",
       "      <td>26116.40</td>\n",
       "      <td>2</td>\n",
       "      <td>130.58200</td>\n",
       "      <td>60741.70795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>229</td>\n",
       "      <td>309</td>\n",
       "      <td>35357.32205</td>\n",
       "      <td>9240.92205</td>\n",
       "      <td>25939.08</td>\n",
       "      <td>2</td>\n",
       "      <td>12969.54</td>\n",
       "      <td>([[12421.88, 12476.76, 12293.34, 12302.46, 235...</td>\n",
       "      <td>(S, H)</td>\n",
       "      <td>S</td>\n",
       "      <td>35050.30665</td>\n",
       "      <td>35050.30665</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>129.69540</td>\n",
       "      <td>60871.40335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>230</td>\n",
       "      <td>310</td>\n",
       "      <td>35050.30665</td>\n",
       "      <td>35050.30665</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>13020.83</td>\n",
       "      <td>([[12303.92, 12382.16, 12196.87, 12216.4, 2090...</td>\n",
       "      <td>(H, B)</td>\n",
       "      <td>B</td>\n",
       "      <td>34920.09835</td>\n",
       "      <td>8878.43835</td>\n",
       "      <td>26041.66</td>\n",
       "      <td>2</td>\n",
       "      <td>130.20830</td>\n",
       "      <td>61001.61165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>231</td>\n",
       "      <td>311</td>\n",
       "      <td>34920.09835</td>\n",
       "      <td>8878.43835</td>\n",
       "      <td>25628.70</td>\n",
       "      <td>2</td>\n",
       "      <td>12814.35</td>\n",
       "      <td>([[12215.92, 12326.47, 12176.11, 12262.89, 273...</td>\n",
       "      <td>(S, H)</td>\n",
       "      <td>S</td>\n",
       "      <td>34378.99485</td>\n",
       "      <td>34378.99485</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>128.14350</td>\n",
       "      <td>61129.75515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>232</td>\n",
       "      <td>312</td>\n",
       "      <td>34378.99485</td>\n",
       "      <td>34378.99485</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12866.78</td>\n",
       "      <td>([[12266.64, 12659.82, 12266.47, 12654.36, 295...</td>\n",
       "      <td>(H,)</td>\n",
       "      <td>H</td>\n",
       "      <td>34378.99485</td>\n",
       "      <td>34378.99485</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>61129.75515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Step  idx  Portfolio Value          Cash  Stock Value  Stock Holdings  \\\n",
       "0       1   81     100000.00000  100000.00000         0.00               0   \n",
       "1       2   82      99530.14635    5559.41635     93974.72               7   \n",
       "2       3   83      99064.26275   99064.26275         0.00               0   \n",
       "3       4   84      98598.93740    5533.86740     94376.45               7   \n",
       "4       5   85      99438.43515   99438.43515         0.00               0   \n",
       "..    ...  ...              ...           ...          ...             ...   \n",
       "227   228  308      35487.90405   35487.90405         0.00               0   \n",
       "228   229  309      35357.32205    9240.92205     25939.08               2   \n",
       "229   230  310      35050.30665   35050.30665         0.00               0   \n",
       "230   231  311      34920.09835    8878.43835     25628.70               2   \n",
       "231   232  312      34378.99485   34378.99485         0.00               0   \n",
       "\n",
       "     Stock Price                                              State  \\\n",
       "0       13424.39  ([[13062.75, 13137.76, 13041.3, 13136.14, 2489...   \n",
       "1       13424.96  ([[13133.94, 13256.33, 13130.53, 13211.88, 251...   \n",
       "2       13295.01  ([[13206.65, 13246.82, 13196.03, 13241.38, 247...   \n",
       "3       13482.35  ([[13243.08, 13284.53, 13228.78, 13264.62, 236...   \n",
       "4       13553.73  ([[13264.13, 13317.69, 13260.8, 13312.97, 2061...   \n",
       "..           ...                                                ...   \n",
       "227     13058.20  ([[12531.79, 12531.95, 12376.7, 12422.86, 2350...   \n",
       "228     12969.54  ([[12421.88, 12476.76, 12293.34, 12302.46, 235...   \n",
       "229     13020.83  ([[12303.92, 12382.16, 12196.87, 12216.4, 2090...   \n",
       "230     12814.35  ([[12215.92, 12326.47, 12176.11, 12262.89, 273...   \n",
       "231     12866.78  ([[12266.64, 12659.82, 12266.47, 12654.36, 295...   \n",
       "\n",
       "    Available Actions Env Action  New Portfolio Value     New Cash  \\\n",
       "0              (H, B)          B          99530.14635   5559.41635   \n",
       "1              (S, H)          S          99064.26275  99064.26275   \n",
       "2              (H, B)          B          98598.93740   5533.86740   \n",
       "3              (S, H)          S          99438.43515  99438.43515   \n",
       "4              (H, B)          B          98964.05460   4087.94460   \n",
       "..                ...        ...                  ...          ...   \n",
       "227            (H, B)          B          35357.32205   9240.92205   \n",
       "228            (S, H)          S          35050.30665  35050.30665   \n",
       "229            (H, B)          B          34920.09835   8878.43835   \n",
       "230            (S, H)          S          34378.99485  34378.99485   \n",
       "231              (H,)          H          34378.99485  34378.99485   \n",
       "\n",
       "     New Stock Value  New Stock Holdings  New Commission Cost  \\\n",
       "0           93970.73                   7            469.85365   \n",
       "1               0.00                   0            469.87360   \n",
       "2           93065.07                   7            465.32535   \n",
       "3               0.00                   0            471.88225   \n",
       "4           94876.11                   7            474.38055   \n",
       "..               ...                 ...                  ...   \n",
       "227         26116.40                   2            130.58200   \n",
       "228             0.00                   0            129.69540   \n",
       "229         26041.66                   2            130.20830   \n",
       "230             0.00                   0            128.14350   \n",
       "231             0.00                   0              0.00000   \n",
       "\n",
       "     Total Commission Cost  \n",
       "0                469.85365  \n",
       "1                939.72725  \n",
       "2               1405.05260  \n",
       "3               1876.93485  \n",
       "4               2351.31540  \n",
       "..                     ...  \n",
       "227            60741.70795  \n",
       "228            60871.40335  \n",
       "229            61001.61165  \n",
       "230            61129.75515  \n",
       "231            61129.75515  \n",
       "\n",
       "[232 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profit Action</th>\n",
       "      <th>profit Action Type</th>\n",
       "      <th>profit Q_Val Sell</th>\n",
       "      <th>profit Q_Val Hold</th>\n",
       "      <th>profit Q_Val Buy</th>\n",
       "      <th>profit Reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>-0.075722</td>\n",
       "      <td>-0.048623</td>\n",
       "      <td>1.602233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.029220</td>\n",
       "      <td>-0.080427</td>\n",
       "      <td>-0.008248</td>\n",
       "      <td>-0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.023580</td>\n",
       "      <td>-0.055169</td>\n",
       "      <td>-0.027450</td>\n",
       "      <td>2.560434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.039352</td>\n",
       "      <td>-0.069941</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>-0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>Best</td>\n",
       "      <td>-0.000628</td>\n",
       "      <td>-0.138312</td>\n",
       "      <td>0.044113</td>\n",
       "      <td>-0.058213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>B</td>\n",
       "      <td>Best</td>\n",
       "      <td>-0.015168</td>\n",
       "      <td>-0.171995</td>\n",
       "      <td>0.083201</td>\n",
       "      <td>-2.391754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>S</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.028471</td>\n",
       "      <td>-0.133362</td>\n",
       "      <td>0.032458</td>\n",
       "      <td>-0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>B</td>\n",
       "      <td>Best</td>\n",
       "      <td>-0.016968</td>\n",
       "      <td>-0.145591</td>\n",
       "      <td>0.056702</td>\n",
       "      <td>-1.448832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>S</td>\n",
       "      <td>Best</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>-0.117988</td>\n",
       "      <td>-0.004962</td>\n",
       "      <td>-0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>H</td>\n",
       "      <td>Best</td>\n",
       "      <td>-0.017081</td>\n",
       "      <td>-0.121157</td>\n",
       "      <td>-0.009653</td>\n",
       "      <td>-0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    profit Action profit Action Type  profit Q_Val Sell  profit Q_Val Hold  \\\n",
       "0               B               Best           0.010607          -0.075722   \n",
       "1               S               Best           0.029220          -0.080427   \n",
       "2               B               Best           0.023580          -0.055169   \n",
       "3               S               Best           0.039352          -0.069941   \n",
       "4               B               Best          -0.000628          -0.138312   \n",
       "..            ...                ...                ...                ...   \n",
       "227             B               Best          -0.015168          -0.171995   \n",
       "228             S               Best           0.028471          -0.133362   \n",
       "229             B               Best          -0.016968          -0.145591   \n",
       "230             S               Best           0.041449          -0.117988   \n",
       "231             H               Best          -0.017081          -0.121157   \n",
       "\n",
       "     profit Q_Val Buy  profit Reward  \n",
       "0           -0.048623       1.602233  \n",
       "1           -0.008248      -0.020000  \n",
       "2           -0.027450       2.560434  \n",
       "3            0.010973      -0.020000  \n",
       "4            0.044113      -0.058213  \n",
       "..                ...            ...  \n",
       "227          0.083201      -2.391754  \n",
       "228          0.032458      -0.020000  \n",
       "229          0.056702      -1.448832  \n",
       "230         -0.004962      -0.020000  \n",
       "231         -0.009653      -0.020000  \n",
       "\n",
       "[232 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DJI: Step data exported to DJI_training.csv\n"
     ]
    }
   ],
   "source": [
    "display(env['DJI'].get_step_data())\n",
    "display(best_ddqn_agent.get_step_data())\n",
    "env['DJI'].csv_export_step_data(\"DJI_training.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Objective function, need to create agent name before to link agent with enviornment\n",
    "agent_name = 'REWARD_DDQN_AGENT'\n",
    "agent_path = export_path + '/' + agent_name\n",
    "metric = 'val_ror'\n",
    "\n",
    "for key, env in environments.items():\n",
    "  \n",
    "        env.add_agent(agent_name)\n",
    "        env.set_decision_agent(agent_name)\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # Define the hyperparameters to search over\n",
    "    \n",
    "    ## NN hyperparameters\n",
    "    sug_hidden_layers = trial.suggest_int('hidden_layers', low=1, high=3)\n",
    "    sug_hidden_size = trial.suggest_int('hidden_size', low=256, high=1280, step=64)\n",
    "    sug_update_q_freq = trial.suggest_int('update_q_freq',low=1,high=5)\n",
    "    sug_update_tgt_freq = trial.suggest_int('update_tgt_freq',low=10,high=50,step=10)\n",
    "    \n",
    "    ## Function Passing\n",
    "    activation_functions = {\n",
    "    'RELU': nn.ReLU(),\n",
    "    'LRELU': nn.LeakyReLU(),\n",
    "    'GELU': nn.GELU(),\n",
    "    'TANH': nn.Tanh()\n",
    "    }\n",
    "    sug_activation_function_name = trial.suggest_categorical('activation_function', list(activation_functions.keys()))\n",
    "    sug_activation_function = activation_functions[sug_activation_function_name]\n",
    "    \n",
    "    ## Optimizer hyperparameters\n",
    "    sug_opt_lre = trial.suggest_float('opt_lre',0.0001,0.1,log=True)\n",
    "    ## Memory Replay hyperparameters\n",
    "    sug_buffer_size = trial.suggest_int('buffer_size',low=100,high=1500,step=100)\n",
    "    sug_batch_size = trial.suggest_int('batch_size',low=10,high=150,step=10)\n",
    "\n",
    "    # Saving Setup\n",
    "    ## Current Parameter Values:\n",
    "    cur_n_fcl = trial.params['hidden_layers']\n",
    "    cur_fcl_size = trial.params['hidden_size']\n",
    "    cur_q_freq = trial.params['update_q_freq']\n",
    "    cur_tgt_freq = trial.params['update_tgt_freq']\n",
    "    cur_act_func = trial.params['activation_function']\n",
    "    cur_lre = decimal_to_text(trial.params['opt_lre'])\n",
    "    cur_buf_size = trial.params['buffer_size']\n",
    "    cur_bat_size = trial.params['batch_size']\n",
    "    \n",
    "    ## Create Notation for Hyperparameter Setup    \n",
    "    test_name = (f'{cur_n_fcl}FC{cur_fcl_size}_{cur_act_func}_' +\n",
    "                f'BT{cur_bat_size}BF{cur_buf_size}_Q{cur_q_freq}_' +\n",
    "                f'TGT{cur_tgt_freq}_LR{cur_lre}')\n",
    "    \n",
    "    ## Create Dir to save results\n",
    "    test_name_path =  agent_path + '/' + test_name \n",
    "    if not os.path.exists(test_name_path):\n",
    "        os.makedirs(test_name_path)\n",
    "        print(f\"Directory '{test_name_path}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{test_name_path}' already exists.\")    \n",
    "    \n",
    "    # Create Agent with hyperparameters  \n",
    "    best_ddqn_agent = DdqnAgent(name=agent_name,\n",
    "                        environment=None,\n",
    "                        reward_function = future_profit,\n",
    "                        reward_params = {'n':5},\n",
    "                        env_state_mod_func = flatten_state,     \n",
    "                        input_size= 13,\n",
    "                        hidden_size= sug_hidden_size, \n",
    "                        output_size=3, \n",
    "                        activation_function = sug_activation_function,\n",
    "                        num_hidden_layers = sug_hidden_layers,                  \n",
    "                        buffer_size= sug_buffer_size, \n",
    "                        batch_size = sug_batch_size,\n",
    "                        opt_lr= sug_opt_lre,\n",
    "                        alpha = ALPHA,\n",
    "                        gamma = GAMMA,\n",
    "                        opt_wgt_dcy = 0.0,\n",
    "                        dropout_rate = 0.25,                \n",
    "                        device = device)\n",
    "\n",
    "    # Training Model\n",
    "    for key, env in environments.items():\n",
    "        \n",
    "        if key in trn_keys:\n",
    "            \n",
    "            best_ddqn_agent.set_environment(env)\n",
    "            best_ddqn_agent.train(start_idx=training_range[0],\n",
    "                        end_idx=training_range[1],\n",
    "                        training_episodes= 100,\n",
    "                        epsilon_decya_func= linear_decay,\n",
    "                        initial_epsilon= 0.9,\n",
    "                        final_epsilon= 0.1,\n",
    "                        update_q_freq= sug_update_q_freq,\n",
    "                        update_tgt_freq= sug_update_tgt_freq,\n",
    "                        save_path = export_path,\n",
    "                        val_start_idx = validation_range[0],\n",
    "                        val_end_idx = validation_range[1],\n",
    "                        early_stop = True,\n",
    "                        stop_metric = metric,\n",
    "                        stop_patience = 20,\n",
    "                        stop_delta = 0.001)\n",
    "        \n",
    "            ## Export Training Session Data to CSV\n",
    "            ddqn_trn = best_ddqn_agent.get_training_episodic_data()\n",
    "            trn_df_file_name  = f'TRN-{key}' + test_name + '.csv'\n",
    "            trn_df_save_path = test_name_path + '/' + trn_df_file_name\n",
    "            ddqn_trn.to_csv(trn_df_save_path)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Test Model\n",
    "    \n",
    "    \n",
    "    scores = []\n",
    "    for key, env in environments.items():\n",
    "    \n",
    "        if key in tst_keys:\n",
    "            \n",
    "            best_ddqn_agent.set_environment(env)              \n",
    "            best_ddqn_agent.test(start_idx = testing_range[0],\n",
    "                        end_idx = testing_range[1], \n",
    "                        testing_episodes=1)\n",
    "\n",
    "            ## Save Test Metric Result(s) into \n",
    "            ddqn_tst = best_ddqn_agent.get_testing_episodic_data()\n",
    "            score = ddqn_tst['Total Reward'].mean()\n",
    "            scores.append(score)\n",
    "    \n",
    "            ## Export Test data\n",
    "            a = env.get_step_data()\n",
    "            b = best_ddqn_agent.get_step_data()\n",
    "            combined_df = pd.concat([a,b],axis=1)\n",
    "            tst_df_file_name  = f'TST-{key}' + test_name + '.csv'\n",
    "            trn_df_save_path = test_name_path + '/' + tst_df_file_name\n",
    "            combined_df.to_csv(trn_df_save_path)\n",
    "\n",
    "            ## Generate Trading Graphic\n",
    "            tst_graph_file_name = trn_df_save_path[:-4] + '.png'\n",
    "            agentperform.agent_stock_performance(env.stock_price_data[testing_range[0]:testing_range[1]],\n",
    "                                                combined_df['Env Action'].to_numpy(),\n",
    "                                                key,\n",
    "                                                best_ddqn_agent.get_name(),\n",
    "                                                display_graph=True,\n",
    "                                                save_graphic=True,\n",
    "                                                path_file=tst_graph_file_name)\n",
    "\n",
    "    mean = np.mean(scores)\n",
    "    return mean\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best value: \", study.best_value)\n",
    "print(\"Best params: \", study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MADDQN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
