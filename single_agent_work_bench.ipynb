{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in another environment (e.g., VS Code)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Code specific to Google Colab\n",
    "    print(\"Running in Google Colab\")\n",
    "\n",
    "    # Additional setup commands for Colab\n",
    "    !pip install neuralforecast\n",
    "    !pip install gymnasium\n",
    "    !pip install QuantStats\n",
    "else:\n",
    "    # Code for other environments (e.g., VS Code)\n",
    "    print(\"Running in another environment (e.g., VS Code)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install RL Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # Retrive required files\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/environments/stockenv.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/utilities/cleandata.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/utilities/data.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/utilities/epsilon_decay.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/utilities/agentperform.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/utilities/prob_evaluate.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/agents/ddqn.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/agents/random.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/agents/baseagent.py\n",
    "    !wget --recursive --no-parent --cut-dirs=4 -P /content https://raw.githubusercontent.com//CodeBeckZero/MADDQN/main/rewards/stockmarket.py            \n",
    "    # Move all directories and files from content/raw.githubusercontent.com to content/\n",
    "    !mv /content/raw.githubusercontent.com/* /content/\n",
    "\n",
    "    # Delete the raw.githubusercontent.com directory\n",
    "    !rm -rf /content/raw.githubusercontent.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activate Python Libraries & Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU support) is not available. PyTorch is running on CPU.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import optuna\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import utilities.agentperform as agentperform\n",
    "import utilities.cleandata as cln \n",
    "from utilities.epsilon_decay import linear_decay\n",
    "from utilities.data import UniStockEnvDataStruct, TimesNetProcessing\n",
    "from agents.ddqn import DdqnAgent\n",
    "from agents.random import RandomAgent\n",
    "from rewards.stockmarket import future_profit, risk_reward\n",
    "from environments.stockenv import ContinuousOHLCVEnv\n",
    "from datetime import datetime\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.models import TimesNet\n",
    "from neuralforecast.losses.numpy import mae, mse\n",
    "import logging\n",
    "\n",
    "\n",
    "# \n",
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").addHandler(logging.NullHandler())\n",
    "logging.getLogger(\"pytorch_lightning.accelerators.cuda\").addHandler(logging.NullHandler())\n",
    "os.environ['NIXTLA_ID_AS_COL'] = '1' # Prevent Warning \n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    # Python random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # If you are using CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "        # Additional settings to force determinism in your operations:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device\n",
    "    device = torch.cuda.current_device()\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"CUDA (GPU support) is not available. PyTorch is running on CPU.\")\n",
    "\n",
    "\n",
    "def decimal_to_text(decimal_number):\n",
    "    # Remove the decimal point and convert to integer\n",
    "    integer_part = int(decimal_number * 1000)\n",
    "    # Convert the integer to text\n",
    "    text_representation = str(integer_part)\n",
    "    return text_representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters & CSV Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "if not IN_COLAB:\n",
    "    pwd = \"C:/programming/MADDQN\"\n",
    "    sys.path.append(pwd)\n",
    "    \n",
    "    # Output Path Location for CSV export\n",
    "    export_path = pwd + \"/output_data\"\n",
    "\n",
    "# Input Data Location, File Name, Stock name for labels\n",
    "input_url = 'https://raw.githubusercontent.com/CodeBeckZero/MADDQN/main/input_data'\n",
    "\n",
    "stock_inputs ={'DJI':'^DJI_daily.csv',\n",
    "               'NDAQ': '^IXIC_daily.csv',\n",
    "               'SP500': '^SPX_daily.csv',\n",
    "               'AAPL': 'AAPL_daily.csv',\n",
    "               'AMZN': 'AMZN_daily.csv',\n",
    "               'GOOGL': 'GOOGL_daily.csv',\n",
    "               'MSFT': 'MSFT_daily.csv',\n",
    "               'SINE': 'sine_wave_daily.csv',\n",
    "               'FORD': 'F_daily.csv',\n",
    "               'JNJ': 'JNJ_daily.csv',\n",
    "               'NEE': 'NEE_daily.csv',\n",
    "               'PFE': 'PFE_daily.csv',\n",
    "               'TSLA': 'TSLA_daily.csv',\n",
    "               'COKE': 'COKE_daily.csv',\n",
    "               'PG': 'PG_daily.csv'}\n",
    "\n",
    "# Training Inputs\n",
    "trn_keys = ['DJI','NDAQ','SP500']\n",
    "\n",
    "# Validation Inputs\n",
    "val_keys = trn_keys\n",
    "\n",
    "# Testing Inputs\n",
    "tst_keys = ['AAPL','AMZN','GOOGL','MSFT','FORD','JNJ','NEE','PFE','TSLA','COKE','PG']\n",
    "\n",
    "window_size = 28 # Needs to match the size Timesnet is trained on\n",
    "price_based_on = 'close'\n",
    "columns = ['open','high','low','close','volume']\n",
    "\n",
    "\n",
    "# Metrics Interested in\n",
    "metrics = ['n_trades','n_wins', 'win_percentage','cumulative_return','sortino','max_drawdown','sharpe', 'trade_dur_avg']\n",
    "\n",
    "aval_metrics_rank_dic = {'n_trades':'max','n_wins': 'max' ,'n_losses':'max','win_percentage':'max','cumulative_return':'max', \n",
    "                 'sortino':'max','max_drawdown':'min', 'sharpe':'max', 'trade_dur_avg':'max', 'trade_dur_min':'max',\n",
    "                 'trade_dur_max':'max','buy_hold':'max'}\n",
    "## See agentperform.py -> results dictionary for options\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Enviornment Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "c:\\Users\\beckm\\anaconda3\\envs\\MADDQN\\Lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "env_data = {}\n",
    "env = {}\n",
    "\n",
    "for stock, file in stock_inputs.items():\n",
    "    if stock in set(trn_keys + val_keys + tst_keys):\n",
    "        # Import\n",
    "        df = cln.YAHOO_csv_input(file, input_url)\n",
    "        data_dic = UniStockEnvDataStruct(df,price_based_on,window_size)\n",
    "        env_data[stock] = data_dic\n",
    "        env[stock] = ContinuousOHLCVEnv(name=stock,\n",
    "                                        ohlcv_data = env_data[stock]['rw_raw_env'] ,\n",
    "                                        stock_price_data= env_data[stock]['rw_raw_price_env'],\n",
    "                                        commission_rate=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workbench Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_discovery = False                 # Limited Exploratory Hyperparmater Discover for RL Agent\n",
    "n_prediction = 5                            # Number of price predictions in the Future by TimesNet (Required for RL agent's input layer)\n",
    "train_tn_model = False                      # Need to Train TimesNet Preprocessing model (processed every cycle)\n",
    "import_tn_model = False                     # Importing TimesNet Preprocessing model (processed every cycle)\n",
    "import_tn_csvs = True                       # Use Imported CSVs from Preprocessing model (no processing, straight to RL agent)\n",
    "tn_path = pwd + '/gen_data/timesnet/'       # Location of\n",
    "no_tn_preprocessing = False                 #\n",
    "\n",
    "timesnet = TimesNetProcessing(env_data)\n",
    "\n",
    "env_mod_func_dic = {'train': timesnet.process,\n",
    "               'import':timesnet.process,\n",
    "               'csv':timesnet.csv_process,\n",
    "               'none': None}\n",
    "\n",
    "if  train_tn_model ^ import_tn_model ^ import_tn_csvs ^ no_tn_preprocessing:\n",
    "    if train_tn_model or import_tn_model:\n",
    "        env_mod_func = env_mod_func_dic['train']\n",
    "    if import_tn_csvs:\n",
    "        env_mod_func = env_mod_func_dic['csv']\n",
    "    if no_tn_preprocessing:\n",
    "        env_mod_func = env_mod_func_dic['none']\n",
    "else:\n",
    "    raise ValueError(\"Only one TimesNet Preprocessing Options can be selected\")\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_function(env):\n",
    "    metric = env.step_info[-1]['New Portfolio Value'] -  env.step_info[-1]['Portfolio Value']\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimesNet Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_tn_model:\n",
    "    \n",
    "    model = TimesNet(h = n_prediction,          # Forecast horizon\n",
    "                    input_size = window_size,   # Length of Batches\n",
    "                    batch_size = 1,             # Number of timeseries to predict\n",
    "                    #futr_exog_list = remaining_columns,\n",
    "                    hidden_size = 128,          # Size of embedding for embedding and encoders,\n",
    "                    dropout = 0.40,             # Dropout for embeddings\n",
    "                    conv_hidden_size = 3,       # Channels for the inception block\n",
    "                    top_k = 5,                  # Top num of periods from FFT considered\n",
    "                    num_kernels = 13,           # number of kernels for the inception block\n",
    "                    encoder_layers = 3,         # num of encoders\n",
    "                    max_steps = 1000,           # of training steps\n",
    "                    early_stop_patience_steps = 10, #early stoppage on validation\n",
    "                    val_check_steps = 100,      # Val check every X steps,\n",
    "                    windows_batch_size = 150,   # Number of windows in training epoch,\n",
    "                    num_workers_loader = 7,\n",
    "                    learning_rate = 0.0003,\n",
    "                    random_seed = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_tn_model:\n",
    "  nf = NeuralForecast(models=[model], freq='d')\n",
    "  results = {}\n",
    "  for key in trn_keys:\n",
    "    results[key] = nf.fit(df=env[key],val_size=0.2)\n",
    "\n",
    "  nf.save(path= tn_path,\n",
    "          model_index=None,\n",
    "          overwrite=True,\n",
    "          save_dataset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if import_tn_model:\n",
    "# Define the correct path\n",
    "  if IN_COLAB:\n",
    "    \n",
    "    model_path = os.path.join(os.getcwd(), 'gen_data', 'timesnet')\n",
    "\n",
    "    # Ensure the directory and file exist\n",
    "    if os.path.exists(model_path):\n",
    "        nf = NeuralForecast.load(path=model_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Model path {model_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if import_tn_csvs:\n",
    "\n",
    "    if IN_COLAB:\n",
    "        # Input Data Location, File Name, Stock name for labels\n",
    "        csv_path = 'https://raw.githubusercontent.com/CodeBeckZero/MADDQN/main/gen_data/csvs/'\n",
    "\n",
    "    else:\n",
    "        csv_path  = pwd +'/gen_data/csvs/'\n",
    "\n",
    "    stock_tn ={'DJI':'DJI_tn.csv',\n",
    "                'NDAQ': 'NDAQ_tn.csv',\n",
    "                'SP500': 'SP500_tn.csv',\n",
    "                'AAPL': 'AAPL_tn.csv',\n",
    "                'AMZN': 'AMZN_tn.csv',\n",
    "                'GOOGL': 'GOOGL_tn.csv',\n",
    "                'MSFT': 'MSFT_tn.csv',\n",
    "                'FORD': 'FORD_tn.csv',\n",
    "                'JNJ': 'JNJ_tn.csv',\n",
    "                'NEE': 'NEE_tn.csv',\n",
    "                'PFE': 'PFE_tn.csv',\n",
    "                'TSLA': 'TSLA_tn.csv',\n",
    "                'COKE': 'COKE_tn.csv',\n",
    "                'PG': 'PG_tn.csv'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Hyperparameterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interval Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyperparam_discovery:\n",
    "    # Training Inputs\n",
    "    hyp_training_range = ('2007-01-01','2010-12-31')\n",
    "    hyp_trn_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in hyp_training_range]\n",
    "\n",
    "    # Validation Inputs\n",
    "    hyp_validation_range = ('2013-01-01', '2014-12-31')\n",
    "    hyp_val_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in hyp_validation_range]\n",
    "\n",
    "    # Testing Inputs\n",
    "    hyp_testing_range = ('2016-01-01', '2017-12-31')\n",
    "    hyp_tst_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in hyp_testing_range]\n",
    "\n",
    "    hyp_trn_idx = {}\n",
    "    hyp_val_idx = {}\n",
    "    hyp_tst_idx = {}\n",
    "\n",
    "    for stock, file in stock_inputs.items():\n",
    "        if stock in set(trn_keys + val_keys + tst_keys):\n",
    "            if stock in trn_keys:\n",
    "                hyp_trn_idx[stock] = env_data[stock].gen_rw_idxs(hyp_trn_dt_range)\n",
    "            if stock in val_keys:\n",
    "                hyp_val_idx[stock] = env_data[stock].gen_rw_idxs(hyp_val_dt_range)\n",
    "            if stock in tst_keys:\n",
    "                hyp_tst_idx[stock] = env_data[stock].gen_rw_idxs(hyp_tst_dt_range)\n",
    "\n",
    "    display(hyp_trn_idx,hyp_val_idx,hyp_tst_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Search & Code Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyperparam_discovery:\n",
    "    \n",
    "    # For Objective function, need to create agent name before to link agent with enviornment\n",
    "    agent_name = 'hyp_discovery_agent'\n",
    "    agent_path = export_path + '/' + agent_name\n",
    "    metric = 'val_tot_r'\n",
    "    max_len_buf = np.round(hyp_trn_idx['DJI'][1] - hyp_trn_idx['DJI'][0] + window_size, -2) -10 # manual input, could be error here if \n",
    "    print(f'Max Mem Length: {max_len_buf}')\n",
    "           \n",
    "    def objective(trial):\n",
    "    \n",
    "        # Define the hyperparameters to search over\n",
    "        \n",
    "        ## NN hyperparameters\n",
    "        sug_hidden_layers = trial.suggest_int('hidden_layers', low=1, high=3)\n",
    "        sug_hidden_size = trial.suggest_int('hidden_size', low=64, high=512, step=64)\n",
    "        sug_update_q_freq = trial.suggest_int('update_q_freq',low=1,high=5)\n",
    "        sug_update_tgt_freq = trial.suggest_int('update_tgt_freq',low=5,high=15)\n",
    "        \n",
    "        ## Activation Function Passing\n",
    "        activation_functions = {\n",
    "        'LRELUd': nn.LeakyReLU(),\n",
    "        'LRELUs02': nn.LeakyReLU(negative_slope=0.2),\n",
    "        'GELU': nn.GELU(),\n",
    "        'TANH': nn.Tanh(),\n",
    "        'SELU':nn.SELU(),\n",
    "        'SILU': nn.SiLU()\n",
    "        }\n",
    "        sug_activation_function_name = trial.suggest_categorical('activation_function', list(activation_functions.keys()))\n",
    "        sug_activation_function = activation_functions[sug_activation_function_name]\n",
    "        \n",
    "        \"\"\"\n",
    "        ## Reward Function Passing\n",
    "        reward_functions = {\n",
    "        'profit': future_profit(None,5),\n",
    "        'risk': risk_reward(None,5),\n",
    "        }\n",
    "        sug_reward_function_name = trial.suggest_categorical('reward_function', list(reward_functions.keys()))\n",
    "        sug_reward_function = reward_functions[sug_reward_function_name]\n",
    "        \"\"\"\n",
    "        ## Optimizer hyperparameters\n",
    "        sug_opt_lre = trial.suggest_categorical('opt_lre',[0.0001,0.0005,0.001, 0.005, 0.01, 0.05, 0.1])\n",
    "        sug_gamma = trial.suggest_float('gamma',low=0.90,high=0.99,step=0.01)\n",
    "        ## Memory Replay hyperparameters\n",
    "        sug_buffer_size = trial.suggest_int('buffer_size',low=100,high=max_len_buf,step=10)\n",
    "        sug_batch_size = trial.suggest_int('batch_size',low=10,high=sug_buffer_size,step=5)\n",
    "        \n",
    "        # Saving Setup\n",
    "        ## Current Parameter Values:\n",
    "        cur_n_fcl = trial.params['hidden_layers']\n",
    "        cur_fcl_size = trial.params['hidden_size']\n",
    "        cur_q_freq = trial.params['update_q_freq']\n",
    "        cur_tgt_freq = trial.params['update_tgt_freq']\n",
    "        cur_act_func = trial.params['activation_function']\n",
    "        #cur_rwd_func = trial.params['reward_function']\n",
    "        cur_lre = decimal_to_text(trial.params['opt_lre'])\n",
    "        cur_buf_size = trial.params['buffer_size']\n",
    "        cur_bat_size = trial.params['batch_size']\n",
    "        \n",
    "        ## Create Notation for Hyperparameter Setup    \n",
    "        test_name = (f'{cur_n_fcl}FC{cur_fcl_size}_{cur_act_func}_' +\n",
    "                    f'BT{cur_bat_size}BF{cur_buf_size}_Q{cur_q_freq}_' +\n",
    "                    f'TGT{cur_tgt_freq}_LR{cur_lre}')\n",
    "        \n",
    "        ## Create Dir to save results\n",
    "        test_name_path =  agent_path + '/' + test_name \n",
    "        if not os.path.exists(test_name_path):\n",
    "            os.makedirs(test_name_path)\n",
    "            print(f\"Directory '{test_name_path}' created successfully.\")\n",
    "        else:\n",
    "            print(f\"Directory '{test_name_path}' already exists.\")\n",
    "        \n",
    "        # Create Agent with hyperparameters  \n",
    "        best_agent = DdqnAgent(name=agent_name,\n",
    "                            environment=None,\n",
    "                            reward_function = future_profit,\n",
    "                            reward_params = {'n':5},\n",
    "                            env_state_mod_func = env_mod_func,     \n",
    "                            input_size= 11,\n",
    "                            hidden_size= sug_hidden_size, \n",
    "                            output_size=3, \n",
    "                            activation_function = sug_activation_function,\n",
    "                            num_hidden_layers = sug_hidden_layers,                  \n",
    "                            buffer_size= sug_buffer_size, \n",
    "                            batch_size = sug_batch_size,\n",
    "                            alpha = sug_opt_lre,\n",
    "                            gamma = sug_gamma,\n",
    "                            opt_wgt_dcy = 0.01,\n",
    "                            dropout_rate = 0.25,                \n",
    "                            device = device)\n",
    "        \n",
    "        # Training Model\n",
    "        for key, rl_env in env.items():\n",
    "            \n",
    "            if key in trn_keys:\n",
    "                rl_env.add_agent(agent_name)\n",
    "                rl_env.set_decision_agent(agent_name)\n",
    "                if import_tn_csvs:\n",
    "                    timesnet.upload_csv(f'{csv_path}/{stock_tn[key]}')    #Requires outside variable         \n",
    "                best_agent.set_environment(rl_env)\n",
    "                best_agent.train(start_idx=hyp_trn_idx[key][0],\n",
    "                            end_idx=hyp_trn_idx[key][1],\n",
    "                            training_episodes= 1,\n",
    "                            epsilon_decya_func= linear_decay,\n",
    "                            initial_epsilon= 0.9,\n",
    "                            final_epsilon= 0.1,\n",
    "                            update_q_freq= sug_update_q_freq,\n",
    "                            update_tgt_freq= sug_update_tgt_freq,\n",
    "                            save_path = export_path,\n",
    "                            val_start_idx = hyp_val_idx[key][0],\n",
    "                            val_end_idx = hyp_val_idx[key][1],\n",
    "                            metric_func= metric_function,\n",
    "                            min_training_episodes = 1, \n",
    "                            early_stop = True,\n",
    "                            stop_metric = metric,\n",
    "                            stop_patience = 3,\n",
    "                            stop_delta = 0.001)\n",
    "                rl_env.remove_agent(agent_name)\n",
    "\n",
    "        # Test Model\n",
    "        \n",
    "        scores = []\n",
    "        for key, rl_env in env.items():\n",
    "        \n",
    "            if key in tst_keys:\n",
    "                rl_env.add_agent(agent_name)\n",
    "                rl_env.set_decision_agent(agent_name)\n",
    "                if import_tn_csvs:\n",
    "                    timesnet.upload_csv(f'{csv_path}/{stock_tn[key]}')    #Requires outside variable              \n",
    "                best_agent.set_environment(rl_env)              \n",
    "                best_agent.test(start_idx = hyp_tst_idx[key][0],\n",
    "                            end_idx = hyp_tst_idx[key][1],\n",
    "                            metric_func= metric_function, \n",
    "                            testing_episodes=1)\n",
    "                rl_env.remove_agent(agent_name)\n",
    "\n",
    "                ## Save Test Metric Result(s) into \n",
    "                ddqn_tst = best_agent.get_testing_episodic_data()\n",
    "                score = ddqn_tst['tot_r'].mean()\n",
    "                scores.append(score)\n",
    "        \n",
    "                ## Export Test data\n",
    "                a = rl_env.get_step_data()\n",
    "                b = best_agent.get_step_data()\n",
    "                combined_df = pd.concat([a,b],axis=1)\n",
    "                tst_df_file_name  = f'TST-{key}' + test_name + '.csv'\n",
    "                trn_df_save_path = test_name_path + '/' + tst_df_file_name\n",
    "                combined_df.to_csv(trn_df_save_path)\n",
    "\n",
    "                ## Generate Trading Graphic\n",
    "                tst_graph_file_name = trn_df_save_path[:-4] + '.png'\n",
    "                agentperform.agent_stock_performance(env[key].stock_price_data[hyp_tst_idx[key][0]:hyp_tst_idx[key][1]][:,-1,0], # Selecting all batches, last price of window, closing price\n",
    "                                                    combined_df['Env Action'].to_numpy(),\n",
    "                                                    key,\n",
    "                                                    best_agent.get_name(),\n",
    "                                                    display_graph=False,\n",
    "                                                    save_graphic=True,\n",
    "                                                    path_file=tst_graph_file_name)\n",
    "\n",
    "        mean = np.mean(scores)\n",
    "        return mean\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    print(\"Best value: \", study.best_value)\n",
    "    print(\"Best params: \", study.best_params)\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Type Setup\n",
    "agent_classes = {'profit': DdqnAgent,\n",
    "                 'risk': DdqnAgent}\n",
    "\n",
    "# Mul\n",
    "agent_setup = {'profit': ['profit'],\n",
    "                 'risk': ['risk']}\n",
    "                 #final': ['profit', 'risk'], for multi agent key is decision agent\n",
    "                 #'macro': 'macro', \n",
    "                 #'opt': ['profit', 'risk', 'macro']}\n",
    "                 \n",
    "agent_name_list = list(agent_classes.keys())\n",
    "\n",
    "agent_params = {\n",
    "    agent_name_list[0]:{\n",
    "        'name': agent_name_list[0],\n",
    "        'environment': None,\n",
    "        'reward_function': future_profit,\n",
    "        'reward_params': {'n':5},\n",
    "        'env_state_mod_func': env_mod_func,\n",
    "        'input_size': 11,\n",
    "        'hidden_size': 256,\n",
    "        'output_size':3,\n",
    "        'activation_function': nn.Tanh(),\n",
    "        'num_hidden_layers': 2,\n",
    "        'buffer_size': 150,\n",
    "        'batch_size': 30,\n",
    "        'alpha': 0.005,\n",
    "        'gamma':0.97,\n",
    "        'opt_wgt_dcy': 0.01,\n",
    "        'dropout_rate': 0.25,\n",
    "        'device': device\n",
    "    },\n",
    "    agent_name_list[1]:{\n",
    "        'name': agent_name_list[1],\n",
    "        'environment': None,\n",
    "        'reward_function': risk_reward,\n",
    "        'reward_params': {'n':5},\n",
    "        'env_state_mod_func': env_mod_func,\n",
    "        'input_size': 11,\n",
    "        'hidden_size': 256,\n",
    "        'output_size':3,\n",
    "        'activation_function': nn.Tanh(),\n",
    "        'num_hidden_layers': 2,\n",
    "        'buffer_size': 150,\n",
    "        'batch_size': 30,\n",
    "        'alpha': 0.005,\n",
    "        'gamma':0.97,\n",
    "        'opt_wgt_dcy': 0.01,\n",
    "        'dropout_rate': 0.25,\n",
    "        'device': device\n",
    "    }}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_dic = {}\n",
    "\n",
    "for agent_name, agent_class in agent_classes.items():\n",
    "            selected_agent = agent_class(**agent_params[agent_name])\n",
    "            agents_dic[agent_name] = selected_agent\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Inputs\n",
    "training_range = ('2007-01-01','2009-12-31')\n",
    "trn_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in training_range]\n",
    "\n",
    "# Validation Inputs\n",
    "validation_range = ('2011-01-01', '2011-12-31')\n",
    "val_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in validation_range]\n",
    "\n",
    "# Testing Inputs\n",
    "testing_range = ('2012-01-01', '2012-12-31')\n",
    "tst_dt_range = [datetime.strptime(dt_str, \"%Y-%m-%d\") for dt_str in testing_range]\n",
    "\n",
    "trn_idx = {}\n",
    "val_idx = {}\n",
    "tst_idx = {}\n",
    "\n",
    "for stock, file in stock_inputs.items():\n",
    "    if stock in set(trn_keys + val_keys + tst_keys):\n",
    "        if stock in trn_keys:\n",
    "            trn_idx[stock] = env_data[stock].gen_rw_idxs(trn_dt_range)\n",
    "        if stock in val_keys:\n",
    "            val_idx[stock] = env_data[stock].gen_rw_idxs(val_dt_range)\n",
    "        if stock in tst_keys:\n",
    "            tst_idx[stock] = env_data[stock].gen_rw_idxs(tst_dt_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {'training_episodes': 10,\n",
    "                   'epsilon_decya_func': linear_decay,\n",
    "                   'initial_epsilon': 0.9,\n",
    "                   'final_epsilon': 0.1,\n",
    "                   'update_q_freq': 1,\n",
    "                   'update_tgt_freq': 15,\n",
    "                   'save_path': export_path,\n",
    "                   'metric_func': metric_function,\n",
    "                   'min_training_episodes': 2,\n",
    "                   'early_stop': True,\n",
    "                   'stop_metric': 'Q1_loss',\n",
    "                   'stop_patience': 2,\n",
    "                   'stop_delta': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DJI ENV: Agent profit added\n",
      "DJI ENV: Agent profit assigned as decision agent\n",
      "\n",
      "profit: Training Initialized on DJI[0:728] -> Validation on DJI[1008:1232]\n",
      "profit: EP 5 of 10 Finished -> ΔQ1 = 1.02, ΔQ2 = 0.68 | ∑R = 16.05, μR = 0.02 σR = 2.36 | Loss: Q1_loss = 1.02 -> EarlyStopping counter: 2 out of 2                                                                                                       \n",
      "profit: Early Stoppage on EP 5 -> Best QNet Loaded from EP 3\n",
      "profit: Training finished on DJI[0:728]\n",
      "\n",
      "DJI ENV: Agent profit removed\n",
      "NDAQ ENV: Agent profit added\n",
      "NDAQ ENV: Agent profit assigned as decision agent\n",
      "\n",
      "profit: Training Initialized on NDAQ[0:728] -> Validation on NDAQ[1008:1232]\n",
      "profit: EP 4 of 10 Finished -> ΔQ1 = 0.89, ΔQ2 = 1.18 | ∑R = 33.92, μR = 0.05 σR = 2.80 | Loss: Q1_loss = 0.89 -> EarlyStopping counter: 2 out of 2                                                                                                       \n",
      "profit: Early Stoppage on EP 4 -> Best QNet Loaded from EP 2\n",
      "profit: Training finished on NDAQ[0:728]\n",
      "\n",
      "NDAQ ENV: Agent profit removed\n",
      "SP500 ENV: Agent profit added\n",
      "SP500 ENV: Agent profit assigned as decision agent\n",
      "\n",
      "profit: Training Initialized on SP500[0:728] -> Validation on SP500[1008:1232]\n",
      "profit: EP 6 of 10 Finished -> ΔQ1 = 0.89, ΔQ2 = 1.16 | ∑R = 131.77, μR = 0.18 σR = 2.09 | Loss: Q1_loss = 0.89 -> EarlyStopping counter: 2 out of 2                                                                                                      \n",
      "profit: Early Stoppage on EP 6 -> Best QNet Loaded from EP 4\n",
      "profit: Training finished on SP500[0:728]\n",
      "\n",
      "SP500 ENV: Agent profit removed\n",
      "DJI ENV: Agent risk added\n",
      "DJI ENV: Agent risk assigned as decision agent\n",
      "\n",
      "risk: Training Initialized on DJI[0:728] -> Validation on DJI[1008:1232]\n",
      "risk: EP 5 of 10 Finished -> ΔQ1 = 0.15, ΔQ2 = 0.15 | ∑R = 3.46, μR = 0.00 σR = 0.05 | Loss: Q1_loss = 0.15 -> EarlyStopping counter: 2 out of 2                                                                                                          \n",
      "risk: Early Stoppage on EP 5 -> Best QNet Loaded from EP 3\n",
      "risk: Training finished on DJI[0:728]\n",
      "\n",
      "DJI ENV: Agent risk removed\n",
      "NDAQ ENV: Agent risk added\n",
      "NDAQ ENV: Agent risk assigned as decision agent\n",
      "\n",
      "risk: Training Initialized on NDAQ[0:728] -> Validation on NDAQ[1008:1232]\n",
      "risk: EP 5 of 10 Finished -> ΔQ1 = 0.00, ΔQ2 = 0.00 | ∑R = 3.27, μR = 0.00 σR = 0.06 | Loss: Q1_loss = 0.00 -> EarlyStopping counter: 2 out of 2                                                                                                          \n",
      "risk: Early Stoppage on EP 5 -> Best QNet Loaded from EP 3\n",
      "risk: Training finished on NDAQ[0:728]\n",
      "\n",
      "NDAQ ENV: Agent risk removed\n",
      "SP500 ENV: Agent risk added\n",
      "SP500 ENV: Agent risk assigned as decision agent\n",
      "\n",
      "risk: Training Initialized on SP500[0:728] -> Validation on SP500[1008:1232]\n",
      "risk: EP 4 of 10 Finished -> ΔQ1 = 0.00, ΔQ2 = 0.00 | ∑R = 1.90, μR = 0.00 σR = 0.05 | Loss: Q1_loss = 0.00 -> EarlyStopping counter: 2 out of 2                                                                                                          \n",
      "risk: Early Stoppage on EP 4 -> Best QNet Loaded from EP 2\n",
      "risk: Training finished on SP500[0:728]\n",
      "\n",
      "SP500 ENV: Agent risk removed\n"
     ]
    }
   ],
   "source": [
    "for decision_agent, agents_in_setup in agent_setup.items():\n",
    "    for key in trn_keys:\n",
    "        rl_env = env[key]\n",
    "       \n",
    "        # Using Csvs\n",
    "        if import_tn_csvs:\n",
    "            timesnet.upload_csv(f'{csv_path}/{stock_tn[key]}')\n",
    "        \n",
    "        # Setup agents with environment  \n",
    "        for agent in agents_in_setup:\n",
    "            rl_env.add_agent(agent)\n",
    "            agents_dic[agent].set_environment(rl_env)\n",
    "        rl_env.set_decision_agent(decision_agent)\n",
    "        \n",
    "        # Train Sub-subagents\n",
    "        for agent in agents_in_setup:\n",
    "            if agent is not decision_agent:\n",
    "                agents_dic[agent].train(start_idx=trn_idx[key][0],\n",
    "                                        end_idx=trn_idx[key][1],\n",
    "                                        val_start_idx= val_idx[key][0],\n",
    "                                        val_end_idx=val_idx[key][1],                                    \n",
    "                                        **training_params)\n",
    "        \n",
    "        # Train Decision Agent\n",
    "        agents_dic[decision_agent].train(start_idx=trn_idx[key][0],\n",
    "                                    end_idx=trn_idx[key][1],\n",
    "                                    val_start_idx= val_idx[key][0],\n",
    "                                    val_end_idx=val_idx[key][1],                                    \n",
    "                                    **training_params)\n",
    "        \n",
    "        # Remove Agent\n",
    "        for agent in agents_in_setup:\n",
    "            rl_env.remove_agent(agent)\n",
    "            agents_dic[agent].set_environment(None)\n",
    "        \"\"\"\n",
    "        ## Export Training Session Data to CSV\n",
    "        ddqn_trn = best_ddqn_agent.get_training_episodic_data()\n",
    "        ddqn_trn.to_csv('test.csv')\n",
    "        display(ddqn_trn)\n",
    "        env[key].remove_agent(best_ddqn_agent.get_name())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_params = {DdqnAgent: {\n",
    "                   'metric_func': metric_function,\n",
    "                   'metric_func_arg': {},\n",
    "                   'testing_episodes':3},\n",
    "                  RandomAgent: {\n",
    "                   'metric_func': metric_function,\n",
    "                   'metric_func_arg': {},\n",
    "                   'testing_episodes':100}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL ENV: Agent profit added\n",
      "AAPL ENV: Agent profit assigned as decision agent\n",
      "\n",
      "profit: Testing Initialized on AAPL[1260:1482]\n",
      "profit - AAPL[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = 550.63, μR = 2.48, σR = 1560.83\n",
      "profit: Testing Complete on AAPL[1260:1482]\n",
      "\n",
      "AAPL ENV: Agent profit removed\n",
      "AAPL ENV: Agent risk added\n",
      "AAPL ENV: Agent risk assigned as decision agent\n",
      "\n",
      "risk: Testing Initialized on AAPL[1260:1482]\n",
      "risk - AAPL[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = 0.00, μR = 0.00, σR = 0.00\n",
      "risk: Testing Complete on AAPL[1260:1482]\n",
      "\n",
      "AAPL ENV: Agent risk removed\n",
      "AMZN ENV: Agent profit added\n",
      "AMZN ENV: Agent profit assigned as decision agent\n",
      "\n",
      "profit: Testing Initialized on AMZN[1260:1482]\n",
      "profit - AMZN[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = 12657.01, μR = 57.01, σR = 1765.93\n",
      "profit: Testing Complete on AMZN[1260:1482]\n",
      "\n",
      "AMZN ENV: Agent profit removed\n",
      "AMZN ENV: Agent risk added\n",
      "AMZN ENV: Agent risk assigned as decision agent\n",
      "\n",
      "risk: Testing Initialized on AMZN[1260:1482]\n",
      "risk - AMZN[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = 0.00, μR = 0.00, σR = 0.00\n",
      "risk: Testing Complete on AMZN[1260:1482]\n",
      "\n",
      "AMZN ENV: Agent risk removed\n",
      "GOOGL ENV: Agent profit added\n",
      "GOOGL ENV: Agent profit assigned as decision agent\n",
      "\n",
      "profit: Testing Initialized on GOOGL[1260:1482]\n",
      "profit - GOOGL[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = -15399.42, μR = -69.37, σR = 1079.69\n",
      "profit: Testing Complete on GOOGL[1260:1482]\n",
      "\n",
      "GOOGL ENV: Agent profit removed\n",
      "GOOGL ENV: Agent risk added\n",
      "GOOGL ENV: Agent risk assigned as decision agent\n",
      "\n",
      "risk: Testing Initialized on GOOGL[1260:1482]\n",
      "risk - GOOGL[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = 0.00, μR = 0.00, σR = 0.00\n",
      "risk: Testing Complete on GOOGL[1260:1482]\n",
      "\n",
      "GOOGL ENV: Agent risk removed\n",
      "MSFT ENV: Agent profit added\n",
      "MSFT ENV: Agent profit assigned as decision agent\n",
      "\n",
      "profit: Testing Initialized on MSFT[1260:1482]\n",
      "profit - MSFT[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = -38756.86, μR = -174.58, σR = 802.19\n",
      "profit: Testing Complete on MSFT[1260:1482]\n",
      "\n",
      "MSFT ENV: Agent profit removed\n",
      "MSFT ENV: Agent risk added\n",
      "MSFT ENV: Agent risk assigned as decision agent\n",
      "\n",
      "risk: Testing Initialized on MSFT[1260:1482]\n",
      "risk - MSFT[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = 0.00, μR = 0.00, σR = 0.00\n",
      "risk: Testing Complete on MSFT[1260:1482]\n",
      "\n",
      "MSFT ENV: Agent risk removed\n",
      "FORD ENV: Agent profit added\n",
      "FORD ENV: Agent profit assigned as decision agent\n",
      "\n",
      "profit: Testing Initialized on FORD[1260:1482]\n",
      "profit - FORD[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = -9132.75, μR = -41.14, σR = 1117.05\n",
      "profit: Testing Complete on FORD[1260:1482]\n",
      "\n",
      "FORD ENV: Agent profit removed\n",
      "FORD ENV: Agent risk added\n",
      "FORD ENV: Agent risk assigned as decision agent\n",
      "\n",
      "risk: Testing Initialized on FORD[1260:1482]\n",
      "risk - FORD[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = 0.00, μR = 0.00, σR = 0.00\n",
      "risk: Testing Complete on FORD[1260:1482]\n",
      "\n",
      "FORD ENV: Agent risk removed\n",
      "JNJ ENV: Agent profit added\n",
      "JNJ ENV: Agent profit assigned as decision agent\n",
      "\n",
      "profit: Testing Initialized on JNJ[1260:1482]\n",
      "profit - JNJ[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = -12292.99, μR = -55.37, σR = 502.19\n",
      "profit: Testing Complete on JNJ[1260:1482]\n",
      "\n",
      "JNJ ENV: Agent profit removed\n",
      "JNJ ENV: Agent risk added\n",
      "JNJ ENV: Agent risk assigned as decision agent\n",
      "\n",
      "risk: Testing Initialized on JNJ[1260:1482]\n",
      "risk - JNJ[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = 0.00, μR = 0.00, σR = 0.00\n",
      "risk: Testing Complete on JNJ[1260:1482]\n",
      "\n",
      "JNJ ENV: Agent risk removed\n",
      "NEE ENV: Agent profit added\n",
      "NEE ENV: Agent profit assigned as decision agent\n",
      "\n",
      "profit: Testing Initialized on NEE[1260:1482]\n",
      "profit - NEE[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = -12086.75, μR = -54.44, σR = 654.21\n",
      "profit: Testing Complete on NEE[1260:1482]\n",
      "\n",
      "NEE ENV: Agent profit removed\n",
      "NEE ENV: Agent risk added\n",
      "NEE ENV: Agent risk assigned as decision agent\n",
      "\n",
      "risk: Testing Initialized on NEE[1260:1482]\n",
      "risk - NEE[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = 0.00, μR = 0.00, σR = 0.00\n",
      "risk: Testing Complete on NEE[1260:1482]\n",
      "\n",
      "NEE ENV: Agent risk removed\n",
      "PFE ENV: Agent profit added\n",
      "PFE ENV: Agent profit assigned as decision agent\n",
      "\n",
      "profit: Testing Initialized on PFE[1260:1482]\n",
      "profit - PFE[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = -9093.25, μR = -40.96, σR = 746.24\n",
      "profit: Testing Complete on PFE[1260:1482]\n",
      "\n",
      "PFE ENV: Agent profit removed\n",
      "PFE ENV: Agent risk added\n",
      "PFE ENV: Agent risk assigned as decision agent\n",
      "\n",
      "risk: Testing Initialized on PFE[1260:1482]\n",
      "risk - PFE[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = 0.00, μR = 0.00, σR = 0.00\n",
      "risk: Testing Complete on PFE[1260:1482]\n",
      "\n",
      "PFE ENV: Agent risk removed\n",
      "TSLA ENV: Agent profit added\n",
      "TSLA ENV: Agent profit assigned as decision agent\n",
      "\n",
      "profit: Testing Initialized on TSLA[382:604]\n",
      "profit - TSLA[382:604] - Testing Finished - EP - 3 of 3-> ∑R = -40152.56, μR = -180.87, σR = 1893.01\n",
      "profit: Testing Complete on TSLA[382:604]\n",
      "\n",
      "TSLA ENV: Agent profit removed\n",
      "TSLA ENV: Agent risk added\n",
      "TSLA ENV: Agent risk assigned as decision agent\n",
      "\n",
      "risk: Testing Initialized on TSLA[382:604]\n",
      "risk - TSLA[382:604] - Testing Finished - EP - 3 of 3-> ∑R = 0.00, μR = 0.00, σR = 0.00\n",
      "risk: Testing Complete on TSLA[382:604]\n",
      "\n",
      "TSLA ENV: Agent risk removed\n",
      "COKE ENV: Agent profit added\n",
      "COKE ENV: Agent profit assigned as decision agent\n",
      "\n",
      "profit: Testing Initialized on COKE[1260:1482]\n",
      "profit - COKE[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = -18728.63, μR = -84.36, σR = 869.79\n",
      "profit: Testing Complete on COKE[1260:1482]\n",
      "\n",
      "COKE ENV: Agent profit removed\n",
      "COKE ENV: Agent risk added\n",
      "COKE ENV: Agent risk assigned as decision agent\n",
      "\n",
      "risk: Testing Initialized on COKE[1260:1482]\n",
      "risk - COKE[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = 0.00, μR = 0.00, σR = 0.00\n",
      "risk: Testing Complete on COKE[1260:1482]\n",
      "\n",
      "COKE ENV: Agent risk removed\n",
      "PG ENV: Agent profit added\n",
      "PG ENV: Agent profit assigned as decision agent\n",
      "\n",
      "profit: Testing Initialized on PG[1260:1482]\n",
      "profit - PG[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = -14825.14, μR = -66.78, σR = 616.51\n",
      "profit: Testing Complete on PG[1260:1482]\n",
      "\n",
      "PG ENV: Agent profit removed\n",
      "PG ENV: Agent risk added\n",
      "PG ENV: Agent risk assigned as decision agent\n",
      "\n",
      "risk: Testing Initialized on PG[1260:1482]\n",
      "risk - PG[1260:1482] - Testing Finished - EP - 3 of 3-> ∑R = 0.00, μR = 0.00, σR = 0.00\n",
      "risk: Testing Complete on PG[1260:1482]\n",
      "\n",
      "PG ENV: Agent risk removed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AAPL': {'profit': {'1260:1482': {0: {'n_trades': 12,\n",
       "     'n_wins': 5,\n",
       "     'n_losses': 7,\n",
       "     'win_percentage': 41.66666666666667,\n",
       "     'cumulative_return': 1.1337761512922764,\n",
       "     'sortino': 7.576785390926368,\n",
       "     'max_drawdown': -8.781273057841886,\n",
       "     'sharpe': 3.041354017056678,\n",
       "     'trade_dur_avg': 12.333333333333334,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 48,\n",
       "     'buy_hold': 1.0329171396140748},\n",
       "    1: {'n_trades': 12,\n",
       "     'n_wins': 5,\n",
       "     'n_losses': 7,\n",
       "     'win_percentage': 41.66666666666667,\n",
       "     'cumulative_return': 1.1337761512922764,\n",
       "     'sortino': 7.576785390926368,\n",
       "     'max_drawdown': -8.781273057841886,\n",
       "     'sharpe': 3.041354017056678,\n",
       "     'trade_dur_avg': 12.333333333333334,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 48,\n",
       "     'buy_hold': 1.0329171396140748},\n",
       "    2: {'n_trades': 12,\n",
       "     'n_wins': 5,\n",
       "     'n_losses': 7,\n",
       "     'win_percentage': 41.66666666666667,\n",
       "     'cumulative_return': 1.1337761512922764,\n",
       "     'sortino': 7.576785390926368,\n",
       "     'max_drawdown': -8.781273057841886,\n",
       "     'sharpe': 3.041354017056678,\n",
       "     'trade_dur_avg': 12.333333333333334,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 48,\n",
       "     'buy_hold': 1.0329171396140748}}},\n",
       "  'risk': {'1260:1482': {0: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0329171396140748},\n",
       "    1: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0329171396140748},\n",
       "    2: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0329171396140748}}}},\n",
       " 'AMZN': {'profit': {'1260:1482': {0: {'n_trades': 15,\n",
       "     'n_wins': 8,\n",
       "     'n_losses': 7,\n",
       "     'win_percentage': 53.333333333333336,\n",
       "     'cumulative_return': 1.3082047033370892,\n",
       "     'sortino': 27.306700874971654,\n",
       "     'max_drawdown': -3.633625769281146,\n",
       "     'sharpe': 6.170394008006698,\n",
       "     'trade_dur_avg': 10.133333333333333,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 35,\n",
       "     'buy_hold': 1.3211206896551724},\n",
       "    1: {'n_trades': 15,\n",
       "     'n_wins': 8,\n",
       "     'n_losses': 7,\n",
       "     'win_percentage': 53.333333333333336,\n",
       "     'cumulative_return': 1.3082047033370892,\n",
       "     'sortino': 27.306700874971654,\n",
       "     'max_drawdown': -3.633625769281146,\n",
       "     'sharpe': 6.170394008006698,\n",
       "     'trade_dur_avg': 10.133333333333333,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 35,\n",
       "     'buy_hold': 1.3211206896551724},\n",
       "    2: {'n_trades': 15,\n",
       "     'n_wins': 8,\n",
       "     'n_losses': 7,\n",
       "     'win_percentage': 53.333333333333336,\n",
       "     'cumulative_return': 1.3082047033370892,\n",
       "     'sortino': 27.306700874971654,\n",
       "     'max_drawdown': -3.633625769281146,\n",
       "     'sharpe': 6.170394008006698,\n",
       "     'trade_dur_avg': 10.133333333333333,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 35,\n",
       "     'buy_hold': 1.3211206896551724}}},\n",
       "  'risk': {'1260:1482': {0: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.3211206896551724},\n",
       "    1: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.3211206896551724},\n",
       "    2: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.3211206896551724}}}},\n",
       " 'GOOGL': {'profit': {'1260:1482': {0: {'n_trades': 18,\n",
       "     'n_wins': 7,\n",
       "     'n_losses': 11,\n",
       "     'win_percentage': 38.88888888888889,\n",
       "     'cumulative_return': 1.0139178934474833,\n",
       "     'sortino': 1.6375572082533136,\n",
       "     'max_drawdown': -13.905062388388501,\n",
       "     'sharpe': 0.66556772104467,\n",
       "     'trade_dur_avg': 8.944444444444445,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 63,\n",
       "     'buy_hold': 1.1556728232189972},\n",
       "    1: {'n_trades': 18,\n",
       "     'n_wins': 7,\n",
       "     'n_losses': 11,\n",
       "     'win_percentage': 38.88888888888889,\n",
       "     'cumulative_return': 1.0139178934474833,\n",
       "     'sortino': 1.6375572082533136,\n",
       "     'max_drawdown': -13.905062388388501,\n",
       "     'sharpe': 0.66556772104467,\n",
       "     'trade_dur_avg': 8.944444444444445,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 63,\n",
       "     'buy_hold': 1.1556728232189972},\n",
       "    2: {'n_trades': 18,\n",
       "     'n_wins': 7,\n",
       "     'n_losses': 11,\n",
       "     'win_percentage': 38.88888888888889,\n",
       "     'cumulative_return': 1.0139178934474833,\n",
       "     'sortino': 1.6375572082533136,\n",
       "     'max_drawdown': -13.905062388388501,\n",
       "     'sharpe': 0.66556772104467,\n",
       "     'trade_dur_avg': 8.944444444444445,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 63,\n",
       "     'buy_hold': 1.1556728232189972}}},\n",
       "  'risk': {'1260:1482': {0: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.1556728232189972},\n",
       "    1: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.1556728232189972},\n",
       "    2: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.1556728232189972}}}},\n",
       " 'MSFT': {'profit': {'1260:1482': {0: {'n_trades': 18,\n",
       "     'n_wins': 6,\n",
       "     'n_losses': 12,\n",
       "     'win_percentage': 33.33333333333333,\n",
       "     'cumulative_return': 0.7350291550139918,\n",
       "     'sortino': -7.386502689741757,\n",
       "     'max_drawdown': -30.507162963649257,\n",
       "     'sharpe': -6.940931308214826,\n",
       "     'trade_dur_avg': 6.777777777777778,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 34,\n",
       "     'buy_hold': 0.8704918032786886},\n",
       "    1: {'n_trades': 18,\n",
       "     'n_wins': 6,\n",
       "     'n_losses': 12,\n",
       "     'win_percentage': 33.33333333333333,\n",
       "     'cumulative_return': 0.7350291550139918,\n",
       "     'sortino': -7.386502689741757,\n",
       "     'max_drawdown': -30.507162963649257,\n",
       "     'sharpe': -6.940931308214826,\n",
       "     'trade_dur_avg': 6.777777777777778,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 34,\n",
       "     'buy_hold': 0.8704918032786886},\n",
       "    2: {'n_trades': 18,\n",
       "     'n_wins': 6,\n",
       "     'n_losses': 12,\n",
       "     'win_percentage': 33.33333333333333,\n",
       "     'cumulative_return': 0.7350291550139918,\n",
       "     'sortino': -7.386502689741757,\n",
       "     'max_drawdown': -30.507162963649257,\n",
       "     'sharpe': -6.940931308214826,\n",
       "     'trade_dur_avg': 6.777777777777778,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 34,\n",
       "     'buy_hold': 0.8704918032786886}}},\n",
       "  'risk': {'1260:1482': {0: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 0.8704918032786886},\n",
       "    1: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 0.8704918032786886},\n",
       "    2: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 0.8704918032786886}}}},\n",
       " 'FORD': {'profit': {'1260:1482': {0: {'n_trades': 23,\n",
       "     'n_wins': 12,\n",
       "     'n_losses': 11,\n",
       "     'win_percentage': 52.17391304347826,\n",
       "     'cumulative_return': 1.144266744586227,\n",
       "     'sortino': 5.923980080265614,\n",
       "     'max_drawdown': -9.106766274689537,\n",
       "     'sharpe': 3.0920141148427116,\n",
       "     'trade_dur_avg': 5.565217391304348,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 26,\n",
       "     'buy_hold': 1.0345659163987138},\n",
       "    1: {'n_trades': 23,\n",
       "     'n_wins': 12,\n",
       "     'n_losses': 11,\n",
       "     'win_percentage': 52.17391304347826,\n",
       "     'cumulative_return': 1.144266744586227,\n",
       "     'sortino': 5.923980080265614,\n",
       "     'max_drawdown': -9.106766274689537,\n",
       "     'sharpe': 3.0920141148427116,\n",
       "     'trade_dur_avg': 5.565217391304348,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 26,\n",
       "     'buy_hold': 1.0345659163987138},\n",
       "    2: {'n_trades': 23,\n",
       "     'n_wins': 12,\n",
       "     'n_losses': 11,\n",
       "     'win_percentage': 52.17391304347826,\n",
       "     'cumulative_return': 1.144266744586227,\n",
       "     'sortino': 5.923980080265614,\n",
       "     'max_drawdown': -9.106766274689537,\n",
       "     'sharpe': 3.0920141148427116,\n",
       "     'trade_dur_avg': 5.565217391304348,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 26,\n",
       "     'buy_hold': 1.0345659163987138}}},\n",
       "  'risk': {'1260:1482': {0: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0345659163987138},\n",
       "    1: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0345659163987138},\n",
       "    2: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0345659163987138}}}},\n",
       " 'JNJ': {'profit': {'1260:1482': {0: {'n_trades': 15,\n",
       "     'n_wins': 6,\n",
       "     'n_losses': 9,\n",
       "     'win_percentage': 40.0,\n",
       "     'cumulative_return': 1.0196573034211616,\n",
       "     'sortino': 2.956385807019956,\n",
       "     'max_drawdown': -4.241688458400583,\n",
       "     'sharpe': 1.2481786321826327,\n",
       "     'trade_dur_avg': 9.933333333333334,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 45,\n",
       "     'buy_hold': 1.0755417956656348},\n",
       "    1: {'n_trades': 15,\n",
       "     'n_wins': 6,\n",
       "     'n_losses': 9,\n",
       "     'win_percentage': 40.0,\n",
       "     'cumulative_return': 1.0196573034211616,\n",
       "     'sortino': 2.956385807019956,\n",
       "     'max_drawdown': -4.241688458400583,\n",
       "     'sharpe': 1.2481786321826327,\n",
       "     'trade_dur_avg': 9.933333333333334,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 45,\n",
       "     'buy_hold': 1.0755417956656348},\n",
       "    2: {'n_trades': 15,\n",
       "     'n_wins': 6,\n",
       "     'n_losses': 9,\n",
       "     'win_percentage': 40.0,\n",
       "     'cumulative_return': 1.0196573034211616,\n",
       "     'sortino': 2.956385807019956,\n",
       "     'max_drawdown': -4.241688458400583,\n",
       "     'sharpe': 1.2481786321826327,\n",
       "     'trade_dur_avg': 9.933333333333334,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 45,\n",
       "     'buy_hold': 1.0755417956656348}}},\n",
       "  'risk': {'1260:1482': {0: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0755417956656348},\n",
       "    1: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0755417956656348},\n",
       "    2: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0755417956656348}}}},\n",
       " 'NEE': {'profit': {'1260:1482': {0: {'n_trades': 19,\n",
       "     'n_wins': 8,\n",
       "     'n_losses': 10,\n",
       "     'win_percentage': 42.10526315789473,\n",
       "     'cumulative_return': 1.063790397515479,\n",
       "     'sortino': 5.8908061606955595,\n",
       "     'max_drawdown': -5.710361537819075,\n",
       "     'sharpe': 2.1353632432715344,\n",
       "     'trade_dur_avg': 8.578947368421053,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 59,\n",
       "     'buy_hold': 1.1305500331345262},\n",
       "    1: {'n_trades': 19,\n",
       "     'n_wins': 8,\n",
       "     'n_losses': 10,\n",
       "     'win_percentage': 42.10526315789473,\n",
       "     'cumulative_return': 1.063790397515479,\n",
       "     'sortino': 5.8908061606955595,\n",
       "     'max_drawdown': -5.710361537819075,\n",
       "     'sharpe': 2.1353632432715344,\n",
       "     'trade_dur_avg': 8.578947368421053,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 59,\n",
       "     'buy_hold': 1.1305500331345262},\n",
       "    2: {'n_trades': 19,\n",
       "     'n_wins': 8,\n",
       "     'n_losses': 10,\n",
       "     'win_percentage': 42.10526315789473,\n",
       "     'cumulative_return': 1.063790397515479,\n",
       "     'sortino': 5.8908061606955595,\n",
       "     'max_drawdown': -5.710361537819075,\n",
       "     'sharpe': 2.1353632432715344,\n",
       "     'trade_dur_avg': 8.578947368421053,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 59,\n",
       "     'buy_hold': 1.1305500331345262}}},\n",
       "  'risk': {'1260:1482': {0: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.1305500331345262},\n",
       "    1: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.1305500331345262},\n",
       "    2: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.1305500331345262}}}},\n",
       " 'PFE': {'profit': {'1260:1482': {0: {'n_trades': 18,\n",
       "     'n_wins': 12,\n",
       "     'n_losses': 6,\n",
       "     'win_percentage': 66.66666666666666,\n",
       "     'cumulative_return': 1.0888696705175789,\n",
       "     'sortino': 10.391998782264618,\n",
       "     'max_drawdown': -3.228125672253468,\n",
       "     'sharpe': 4.884413312809725,\n",
       "     'trade_dur_avg': 8.777777777777779,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 28,\n",
       "     'buy_hold': 1.1822734101151728},\n",
       "    1: {'n_trades': 18,\n",
       "     'n_wins': 12,\n",
       "     'n_losses': 6,\n",
       "     'win_percentage': 66.66666666666666,\n",
       "     'cumulative_return': 1.0888696705175789,\n",
       "     'sortino': 10.391998782264618,\n",
       "     'max_drawdown': -3.228125672253468,\n",
       "     'sharpe': 4.884413312809725,\n",
       "     'trade_dur_avg': 8.777777777777779,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 28,\n",
       "     'buy_hold': 1.1822734101151728},\n",
       "    2: {'n_trades': 18,\n",
       "     'n_wins': 12,\n",
       "     'n_losses': 6,\n",
       "     'win_percentage': 66.66666666666666,\n",
       "     'cumulative_return': 1.0888696705175789,\n",
       "     'sortino': 10.391998782264618,\n",
       "     'max_drawdown': -3.228125672253468,\n",
       "     'sharpe': 4.884413312809725,\n",
       "     'trade_dur_avg': 8.777777777777779,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 28,\n",
       "     'buy_hold': 1.1822734101151728}}},\n",
       "  'risk': {'1260:1482': {0: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.1822734101151728},\n",
       "    1: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.1822734101151728},\n",
       "    2: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.1822734101151728}}}},\n",
       " 'TSLA': {'profit': {'382:604': {0: {'n_trades': 23,\n",
       "     'n_wins': 8,\n",
       "     'n_losses': 13,\n",
       "     'win_percentage': 34.78260869565217,\n",
       "     'cumulative_return': 0.7553116835157964,\n",
       "     'sortino': -3.8310370230830744,\n",
       "     'max_drawdown': -38.767432023057665,\n",
       "     'sharpe': -3.1925777451257016,\n",
       "     'trade_dur_avg': 6.260869565217392,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 36,\n",
       "     'buy_hold': 1.067632850241546},\n",
       "    1: {'n_trades': 23,\n",
       "     'n_wins': 8,\n",
       "     'n_losses': 13,\n",
       "     'win_percentage': 34.78260869565217,\n",
       "     'cumulative_return': 0.7553116835157964,\n",
       "     'sortino': -3.8310370230830744,\n",
       "     'max_drawdown': -38.767432023057665,\n",
       "     'sharpe': -3.1925777451257016,\n",
       "     'trade_dur_avg': 6.260869565217392,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 36,\n",
       "     'buy_hold': 1.067632850241546},\n",
       "    2: {'n_trades': 23,\n",
       "     'n_wins': 8,\n",
       "     'n_losses': 13,\n",
       "     'win_percentage': 34.78260869565217,\n",
       "     'cumulative_return': 0.7553116835157964,\n",
       "     'sortino': -3.8310370230830744,\n",
       "     'max_drawdown': -38.767432023057665,\n",
       "     'sharpe': -3.1925777451257016,\n",
       "     'trade_dur_avg': 6.260869565217392,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 36,\n",
       "     'buy_hold': 1.067632850241546}}},\n",
       "  'risk': {'382:604': {0: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.067632850241546},\n",
       "    1: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.067632850241546},\n",
       "    2: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.067632850241546}}}},\n",
       " 'COKE': {'profit': {'1260:1482': {0: {'n_trades': 25,\n",
       "     'n_wins': 10,\n",
       "     'n_losses': 14,\n",
       "     'win_percentage': 40.0,\n",
       "     'cumulative_return': 1.044584520976952,\n",
       "     'sortino': 2.7905540461111524,\n",
       "     'max_drawdown': -6.311336407979084,\n",
       "     'sharpe': 1.481073316481072,\n",
       "     'trade_dur_avg': 5.76,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 32,\n",
       "     'buy_hold': 1.0378224402595349},\n",
       "    1: {'n_trades': 25,\n",
       "     'n_wins': 10,\n",
       "     'n_losses': 14,\n",
       "     'win_percentage': 40.0,\n",
       "     'cumulative_return': 1.044584520976952,\n",
       "     'sortino': 2.7905540461111524,\n",
       "     'max_drawdown': -6.311336407979084,\n",
       "     'sharpe': 1.481073316481072,\n",
       "     'trade_dur_avg': 5.76,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 32,\n",
       "     'buy_hold': 1.0378224402595349},\n",
       "    2: {'n_trades': 25,\n",
       "     'n_wins': 10,\n",
       "     'n_losses': 14,\n",
       "     'win_percentage': 40.0,\n",
       "     'cumulative_return': 1.044584520976952,\n",
       "     'sortino': 2.7905540461111524,\n",
       "     'max_drawdown': -6.311336407979084,\n",
       "     'sharpe': 1.481073316481072,\n",
       "     'trade_dur_avg': 5.76,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 32,\n",
       "     'buy_hold': 1.0378224402595349}}},\n",
       "  'risk': {'1260:1482': {0: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0378224402595349},\n",
       "    1: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0378224402595349},\n",
       "    2: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0378224402595349}}}},\n",
       " 'PG': {'profit': {'1260:1482': {0: {'n_trades': 15,\n",
       "     'n_wins': 6,\n",
       "     'n_losses': 9,\n",
       "     'win_percentage': 40.0,\n",
       "     'cumulative_return': 0.9903315455987829,\n",
       "     'sortino': -0.3170343497750451,\n",
       "     'max_drawdown': -8.762198187023563,\n",
       "     'sharpe': -0.1983885126479948,\n",
       "     'trade_dur_avg': 10.933333333333334,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 46,\n",
       "     'buy_hold': 1.0511897307451472},\n",
       "    1: {'n_trades': 15,\n",
       "     'n_wins': 6,\n",
       "     'n_losses': 9,\n",
       "     'win_percentage': 40.0,\n",
       "     'cumulative_return': 0.9903315455987829,\n",
       "     'sortino': -0.3170343497750451,\n",
       "     'max_drawdown': -8.762198187023563,\n",
       "     'sharpe': -0.1983885126479948,\n",
       "     'trade_dur_avg': 10.933333333333334,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 46,\n",
       "     'buy_hold': 1.0511897307451472},\n",
       "    2: {'n_trades': 15,\n",
       "     'n_wins': 6,\n",
       "     'n_losses': 9,\n",
       "     'win_percentage': 40.0,\n",
       "     'cumulative_return': 0.9903315455987829,\n",
       "     'sortino': -0.3170343497750451,\n",
       "     'max_drawdown': -8.762198187023563,\n",
       "     'sharpe': -0.1983885126479948,\n",
       "     'trade_dur_avg': 10.933333333333334,\n",
       "     'trade_dur_min': 1,\n",
       "     'trade_dur_max': 46,\n",
       "     'buy_hold': 1.0511897307451472}}},\n",
       "  'risk': {'1260:1482': {0: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0511897307451472},\n",
       "    1: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0511897307451472},\n",
       "    2: {'n_trades': 0,\n",
       "     'n_wins': 0,\n",
       "     'n_losses': 0,\n",
       "     'win_percentage': 0,\n",
       "     'cumulative_return': 0,\n",
       "     'sortino': 0,\n",
       "     'max_drawdown': 0,\n",
       "     'sharpe': 0,\n",
       "     'trade_dur_avg': 0,\n",
       "     'trade_dur_min': 0,\n",
       "     'trade_dur_max': 0,\n",
       "     'buy_hold': 1.0511897307451472}}}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_dic_struct = ['stock','agent','test_interval','test_num']\n",
    "results = {}\n",
    "\n",
    "for key in tst_keys:\n",
    "    \n",
    "    # Init Record[Stock]\n",
    "    results[key] = {}\n",
    "    test_key = f'{tst_idx[key][0]}:{tst_idx[key][1]}'\n",
    "    stock_price_data = env_data[key]['rw_raw_price_env'][tst_idx[key][0]:tst_idx[key][1],-1,0]\n",
    "    rl_env = env[key]\n",
    "\n",
    "    for decision_agent, agents_in_setup in agent_setup.items():\n",
    "        \n",
    "        # Init Record[Stock][Agent]\n",
    "        results[key][decision_agent] = {}\n",
    "        \n",
    "        # Init Record[Stock][Agent][test_interval]\n",
    "        results[key][decision_agent][test_key] = {}   # Different Test Keys will need loop\n",
    "        \n",
    "        # Using Csvs       \n",
    "        if import_tn_csvs:\n",
    "            timesnet.upload_csv(f'{csv_path}/{stock_tn[key]}')\n",
    "        \n",
    "        # Setup agents with environment  \n",
    "        for agent in set([decision_agent] + agents_in_setup):\n",
    "            rl_env.add_agent(agent)\n",
    "            agents_dic[agent].set_environment(rl_env)\n",
    "        rl_env.set_decision_agent(decision_agent)\n",
    "               \n",
    "        # Test Decision Agent\n",
    "        params = testing_params[agent_classes[decision_agent]]\n",
    "        agents_dic[decision_agent].test(start_idx=tst_idx[key][0],\n",
    "                                        end_idx=tst_idx[key][1],\n",
    "                                        **params)\n",
    "        test_results = agents_dic[decision_agent].get_testing_episodic_data()\n",
    "        trade_actions_per_test = test_results['tst_actions']\n",
    "               \n",
    "        for idx, action_set in enumerate(trade_actions_per_test):\n",
    "            test_metrics = agentperform.agent_stock_performance(stock_price_ts=np.array(stock_price_data),\n",
    "                                                                trade_ts=np.array(action_set),\n",
    "                                                                stock_name=key,\n",
    "                                                                agent_name=decision_agent,\n",
    "                                                                display_graph=False, \n",
    "                                                                save_graphic= False,\n",
    "                                                                path_file = None)\n",
    "            del test_metrics['stock']\n",
    "            del test_metrics['agent_name']                                                                     \n",
    "            results[key][decision_agent][test_key][idx] = test_metrics\n",
    "        \n",
    "        # Remove Agent\n",
    "        for agent in set([decision_agent] + agents_in_setup):\n",
    "            rl_env.remove_agent(agent)\n",
    "            agents_dic[agent].set_environment(None)\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggreating Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_trades': (            dataset  profit  risk\n",
       "  0    AAPL-1260:1482    12.0   0.0\n",
       "  1    AMZN-1260:1482    15.0   0.0\n",
       "  2   GOOGL-1260:1482    18.0   0.0\n",
       "  3    MSFT-1260:1482    18.0   0.0\n",
       "  4    FORD-1260:1482    23.0   0.0\n",
       "  5     JNJ-1260:1482    15.0   0.0\n",
       "  6     NEE-1260:1482    19.0   0.0\n",
       "  7     PFE-1260:1482    18.0   0.0\n",
       "  8      TSLA-382:604    23.0   0.0\n",
       "  9    COKE-1260:1482    25.0   0.0\n",
       "  10     PG-1260:1482    15.0   0.0,\n",
       "  [('profit', 18.272727272727273), ('risk', 0.0)]),\n",
       " 'n_wins': (            dataset  profit  risk\n",
       "  0    AAPL-1260:1482     5.0   0.0\n",
       "  1    AMZN-1260:1482     8.0   0.0\n",
       "  2   GOOGL-1260:1482     7.0   0.0\n",
       "  3    MSFT-1260:1482     6.0   0.0\n",
       "  4    FORD-1260:1482    12.0   0.0\n",
       "  5     JNJ-1260:1482     6.0   0.0\n",
       "  6     NEE-1260:1482     8.0   0.0\n",
       "  7     PFE-1260:1482    12.0   0.0\n",
       "  8      TSLA-382:604     8.0   0.0\n",
       "  9    COKE-1260:1482    10.0   0.0\n",
       "  10     PG-1260:1482     6.0   0.0,\n",
       "  [('profit', 8.0), ('risk', 0.0)]),\n",
       " 'win_percentage': (            dataset  profit  risk\n",
       "  0    AAPL-1260:1482   41.67   0.0\n",
       "  1    AMZN-1260:1482   53.33   0.0\n",
       "  2   GOOGL-1260:1482   38.89   0.0\n",
       "  3    MSFT-1260:1482   33.33   0.0\n",
       "  4    FORD-1260:1482   52.17   0.0\n",
       "  5     JNJ-1260:1482   40.00   0.0\n",
       "  6     NEE-1260:1482   42.11   0.0\n",
       "  7     PFE-1260:1482   66.67   0.0\n",
       "  8      TSLA-382:604   34.78   0.0\n",
       "  9    COKE-1260:1482   40.00   0.0\n",
       "  10     PG-1260:1482   40.00   0.0,\n",
       "  [('profit', 43.90454545454545), ('risk', 0.0)]),\n",
       " 'cumulative_return': (            dataset  profit  risk\n",
       "  0    AAPL-1260:1482    1.13   0.0\n",
       "  1    AMZN-1260:1482    1.31   0.0\n",
       "  2   GOOGL-1260:1482    1.01   0.0\n",
       "  3    MSFT-1260:1482    0.74   0.0\n",
       "  4    FORD-1260:1482    1.14   0.0\n",
       "  5     JNJ-1260:1482    1.02   0.0\n",
       "  6     NEE-1260:1482    1.06   0.0\n",
       "  7     PFE-1260:1482    1.09   0.0\n",
       "  8      TSLA-382:604    0.76   0.0\n",
       "  9    COKE-1260:1482    1.04   0.0\n",
       "  10     PG-1260:1482    0.99   0.0,\n",
       "  [('profit', 1.0263636363636364), ('risk', 0.0)]),\n",
       " 'sortino': (            dataset  profit  risk\n",
       "  0    AAPL-1260:1482    7.58   0.0\n",
       "  1    AMZN-1260:1482   27.31   0.0\n",
       "  2   GOOGL-1260:1482    1.64   0.0\n",
       "  3    MSFT-1260:1482   -7.39   0.0\n",
       "  4    FORD-1260:1482    5.92   0.0\n",
       "  5     JNJ-1260:1482    2.96   0.0\n",
       "  6     NEE-1260:1482    5.89   0.0\n",
       "  7     PFE-1260:1482   10.39   0.0\n",
       "  8      TSLA-382:604   -3.83   0.0\n",
       "  9    COKE-1260:1482    2.79   0.0\n",
       "  10     PG-1260:1482   -0.32   0.0,\n",
       "  [('profit', 4.8127272727272725), ('risk', 0.0)]),\n",
       " 'max_drawdown': (            dataset  profit  risk\n",
       "  0    AAPL-1260:1482   -8.78   0.0\n",
       "  1    AMZN-1260:1482   -3.63   0.0\n",
       "  2   GOOGL-1260:1482  -13.91   0.0\n",
       "  3    MSFT-1260:1482  -30.51   0.0\n",
       "  4    FORD-1260:1482   -9.11   0.0\n",
       "  5     JNJ-1260:1482   -4.24   0.0\n",
       "  6     NEE-1260:1482   -5.71   0.0\n",
       "  7     PFE-1260:1482   -3.23   0.0\n",
       "  8      TSLA-382:604  -38.77   0.0\n",
       "  9    COKE-1260:1482   -6.31   0.0\n",
       "  10     PG-1260:1482   -8.76   0.0,\n",
       "  [('profit', -12.087272727272728), ('risk', 0.0)]),\n",
       " 'sharpe': (            dataset  profit  risk\n",
       "  0    AAPL-1260:1482    3.04   0.0\n",
       "  1    AMZN-1260:1482    6.17   0.0\n",
       "  2   GOOGL-1260:1482    0.67   0.0\n",
       "  3    MSFT-1260:1482   -6.94   0.0\n",
       "  4    FORD-1260:1482    3.09   0.0\n",
       "  5     JNJ-1260:1482    1.25   0.0\n",
       "  6     NEE-1260:1482    2.14   0.0\n",
       "  7     PFE-1260:1482    4.88   0.0\n",
       "  8      TSLA-382:604   -3.19   0.0\n",
       "  9    COKE-1260:1482    1.48   0.0\n",
       "  10     PG-1260:1482   -0.20   0.0,\n",
       "  [('profit', 1.1263636363636367), ('risk', 0.0)]),\n",
       " 'trade_dur_avg': (            dataset  profit  risk\n",
       "  0    AAPL-1260:1482   12.33   0.0\n",
       "  1    AMZN-1260:1482   10.13   0.0\n",
       "  2   GOOGL-1260:1482    8.94   0.0\n",
       "  3    MSFT-1260:1482    6.78   0.0\n",
       "  4    FORD-1260:1482    5.57   0.0\n",
       "  5     JNJ-1260:1482    9.93   0.0\n",
       "  6     NEE-1260:1482    8.58   0.0\n",
       "  7     PFE-1260:1482    8.78   0.0\n",
       "  8      TSLA-382:604    6.26   0.0\n",
       "  9    COKE-1260:1482    5.76   0.0\n",
       "  10     PG-1260:1482   10.93   0.0,\n",
       "  [('profit', 8.544545454545455), ('risk', 0.0)])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aggerate_results = {}\n",
    "for agent in agent_name_list:\n",
    "    aggerate_results[agent] = {}\n",
    "    for stock in tst_keys:\n",
    "        aggerate_results[agent][stock] = {}\n",
    "        test_key = f'{tst_idx[stock][0]}:{tst_idx[stock][1]}'\n",
    "        aggerate_results[agent][stock][test_key] = {}\n",
    "        values = np.empty((0,len(metrics)))\n",
    "        for test_num in range(testing_params[agent_classes[agent]]['testing_episodes']):\n",
    "\n",
    "            values_array = [results[stock][agent][test_key][test_num][key] for key in metrics]\n",
    "            current_values = np.array(values_array)\n",
    "            values = np.vstack((values,current_values))\n",
    "\n",
    "            means_for_metrics = np.mean(values, axis=0)\n",
    "            std_for_metrics = np.std(values, axis=0)\n",
    "        \n",
    "        for idx,metric in enumerate(metrics):\n",
    "            aggerate_results[agent][stock][test_key][metric] = (means_for_metrics[idx],std_for_metrics[idx])\n",
    "\n",
    "summarized_aggerate_results = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    model_list = []\n",
    "    dataset_name = []\n",
    "    scores = []\n",
    "    for agent in aggerate_results.keys():\n",
    "        \n",
    "        model_list.append(agent)\n",
    "        score_list = []\n",
    "        for stock in aggerate_results[agent].keys():\n",
    "            for test in aggerate_results[agent][stock].keys():\n",
    "                run_name = stock + \"-\" + test\n",
    "                if run_name not in dataset_name:\n",
    "                    dataset_name.append(run_name)\n",
    "                score = aggerate_results[agent][stock][test][metric][0]\n",
    "                score_list.append(np.round(score,2))\n",
    "        scores.append(score_list)\n",
    "\n",
    "    score_array = np.array(scores).T\n",
    "\n",
    "    df = pd.DataFrame(score_array,columns=model_list)\n",
    "    df['dataset'] = dataset_name\n",
    "\n",
    "    column_order = ['dataset'] + [col for col in df.columns if col != 'dataset']\n",
    "    df = df[column_order]\n",
    "\n",
    "    model_means = list(zip(model_list,df[model_list].mean()))\n",
    "\n",
    "    summarized_aggerate_results[metric] = (df, model_means)\n",
    "\n",
    "\n",
    "display(summarized_aggerate_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\MADDQN\\utilities\\prob_evaluate.py:54: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  iman_davenport_stat = ((N-1)*chi_square)/(N*(k-1)-chi_square)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.9646027437307145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('profit', 'risk'), 1.0, 0.5909622353724167, True)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\MADDQN\\utilities\\prob_evaluate.py:54: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  iman_davenport_stat = ((N-1)*chi_square)/(N*(k-1)-chi_square)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.9646027437307145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('profit', 'risk'), 1.0, 0.5909622353724167, True)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\MADDQN\\utilities\\prob_evaluate.py:54: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  iman_davenport_stat = ((N-1)*chi_square)/(N*(k-1)-chi_square)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.9646027437307145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('profit', 'risk'), 1.0, 0.5909622353724167, True)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\MADDQN\\utilities\\prob_evaluate.py:54: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  iman_davenport_stat = ((N-1)*chi_square)/(N*(k-1)-chi_square)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.9646027437307145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('profit', 'risk'), 1.0, 0.5909622353724167, True)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2],\n",
       "       [2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.6041666666666523"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.9646027437307145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('profit', 'risk'), 0.4545454545454546, 0.5909622353724167, False)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\MADDQN\\utilities\\prob_evaluate.py:54: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  iman_davenport_stat = ((N-1)*chi_square)/(N*(k-1)-chi_square)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.9646027437307145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('profit', 'risk'), 1.0, 0.5909622353724167, True)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2],\n",
       "       [2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.6041666666666523"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.9646027437307145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('profit', 'risk'), 0.4545454545454546, 0.5909622353724167, False)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\MADDQN\\utilities\\prob_evaluate.py:54: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  iman_davenport_stat = ((N-1)*chi_square)/(N*(k-1)-chi_square)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.9646027437307145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('profit', 'risk'), 1.0, 0.5909622353724167, True)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utilities import prob_evaluate\n",
    "\n",
    "for metric in metrics:\n",
    "    test = prob_evaluate.generate_rank_array_from_dataframe(summarized_aggerate_results[metric][0],\n",
    "                                                            model_list,equal_rank_behav=\"mean\",\n",
    "                                                            rank_order=aval_metrics_rank_dic[metric])\n",
    "    display(test)\n",
    "    stat, critical_f_value, reject_null_hypo = prob_evaluate.iman_davenport_test(test,0.95)\n",
    "    display(stat, critical_f_value, reject_null_hypo)\n",
    "\n",
    "    results1 = prob_evaluate.nemenyi_test(test,0.95,model_list)\n",
    "    display(results1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ?Final Hypertuning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'environments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m agent_path \u001b[38;5;241m=\u001b[39m export_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m agent_name\n\u001b[0;32m      4\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_ror\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, env \u001b[38;5;129;01min\u001b[39;00m environments\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      8\u001b[0m         env\u001b[38;5;241m.\u001b[39madd_agent(agent_name)\n\u001b[0;32m      9\u001b[0m         env\u001b[38;5;241m.\u001b[39mset_decision_agent(agent_name)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'environments' is not defined"
     ]
    }
   ],
   "source": [
    "# For Objective function, need to create agent name before to link agent with enviornment\n",
    "agent_name = 'REWARD_DDQN_AGENT'\n",
    "agent_path = export_path + '/' + agent_name\n",
    "metric = 'val_ror'\n",
    "\n",
    "for key, env in environments.items():\n",
    "  \n",
    "        env.add_agent(agent_name)\n",
    "        env.set_decision_agent(agent_name)\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # Define the hyperparameters to search over\n",
    "    \n",
    "    ## NN hyperparameters\n",
    "    sug_hidden_layers = trial.suggest_int('hidden_layers', low=1, high=3)\n",
    "    sug_hidden_size = trial.suggest_int('hidden_size', low=256, high=1280, step=64)\n",
    "    sug_update_q_freq = trial.suggest_int('update_q_freq',low=1,high=5)\n",
    "    sug_update_tgt_freq = trial.suggest_int('update_tgt_freq',low=10,high=50,step=10)\n",
    "    \n",
    "    ## Function Passing\n",
    "    activation_functions = {\n",
    "    'RELU': nn.ReLU(),\n",
    "    'LRELU': nn.LeakyReLU(),\n",
    "    'GELU': nn.GELU(),\n",
    "    'TANH': nn.Tanh()\n",
    "    }\n",
    "    sug_activation_function_name = trial.suggest_categorical('activation_function', list(activation_functions.keys()))\n",
    "    sug_activation_function = activation_functions[sug_activation_function_name]\n",
    "    \n",
    "    ## Optimizer hyperparameters\n",
    "    sug_opt_lre = trial.suggest_float('opt_lre',0.0001,0.1,log=True)\n",
    "    ## Memory Replay hyperparameters\n",
    "    sug_buffer_size = trial.suggest_int('buffer_size',low=100,high=1500,step=100)\n",
    "    sug_batch_size = trial.suggest_int('batch_size',low=10,high=150,step=10)\n",
    "\n",
    "    # Saving Setup\n",
    "    ## Current Parameter Values:\n",
    "    cur_n_fcl = trial.params['hidden_layers']\n",
    "    cur_fcl_size = trial.params['hidden_size']\n",
    "    cur_q_freq = trial.params['update_q_freq']\n",
    "    cur_tgt_freq = trial.params['update_tgt_freq']\n",
    "    cur_act_func = trial.params['activation_function']\n",
    "    cur_lre = decimal_to_text(trial.params['opt_lre'])\n",
    "    cur_buf_size = trial.params['buffer_size']\n",
    "    cur_bat_size = trial.params['batch_size']\n",
    "    \n",
    "    ## Create Notation for Hyperparameter Setup    \n",
    "    test_name = (f'{cur_n_fcl}FC{cur_fcl_size}_{cur_act_func}_' +\n",
    "                f'BT{cur_bat_size}BF{cur_buf_size}_Q{cur_q_freq}_' +\n",
    "                f'TGT{cur_tgt_freq}_LR{cur_lre}')\n",
    "    \n",
    "    ## Create Dir to save results\n",
    "    test_name_path =  agent_path + '/' + test_name \n",
    "    if not os.path.exists(test_name_path):\n",
    "        os.makedirs(test_name_path)\n",
    "        print(f\"Directory '{test_name_path}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{test_name_path}' already exists.\")    \n",
    "    \n",
    "    # Create Agent with hyperparameters  \n",
    "    best_ddqn_agent = DdqnAgent(name=agent_name,\n",
    "                        environment=None,\n",
    "                        reward_function = future_profit,\n",
    "                        reward_params = {'n':5},\n",
    "                        env_state_mod_func = flatten_state,     \n",
    "                        input_size= 13,\n",
    "                        hidden_size= sug_hidden_size, \n",
    "                        output_size=3, \n",
    "                        activation_function = sug_activation_function,\n",
    "                        num_hidden_layers = sug_hidden_layers,                  \n",
    "                        buffer_size= sug_buffer_size, \n",
    "                        batch_size = sug_batch_size,\n",
    "                        opt_lr= sug_opt_lre,\n",
    "                        alpha = ALPHA,\n",
    "                        gamma = GAMMA,\n",
    "                        opt_wgt_dcy = 0.0,\n",
    "                        dropout_rate = 0.25,                \n",
    "                        device = device)\n",
    "\n",
    "    # Training Model\n",
    "    for key, env in environments.items():\n",
    "        \n",
    "        if key in trn_keys:\n",
    "            \n",
    "            best_ddqn_agent.set_environment(env)\n",
    "            best_ddqn_agent.train(start_idx=training_range[0],\n",
    "                        end_idx=training_range[1],\n",
    "                        training_episodes= 100,\n",
    "                        epsilon_decya_func= linear_decay,\n",
    "                        initial_epsilon= 0.9,\n",
    "                        final_epsilon= 0.1,\n",
    "                        update_q_freq= sug_update_q_freq,\n",
    "                        update_tgt_freq= sug_update_tgt_freq,\n",
    "                        save_path = export_path,\n",
    "                        val_start_idx = validation_range[0],\n",
    "                        val_end_idx = validation_range[1],\n",
    "                        early_stop = True,\n",
    "                        stop_metric = metric,\n",
    "                        stop_patience = 20,\n",
    "                        stop_delta = 0.001)\n",
    "        \n",
    "            ## Export Training Session Data to CSV\n",
    "            ddqn_trn = best_ddqn_agent.get_training_episodic_data()\n",
    "            trn_df_file_name  = f'TRN-{key}' + test_name + '.csv'\n",
    "            trn_df_save_path = test_name_path + '/' + trn_df_file_name\n",
    "            ddqn_trn.to_csv(trn_df_save_path)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Test Model\n",
    "    \n",
    "    \n",
    "    scores = []\n",
    "    for key, env in environments.items():\n",
    "    \n",
    "        if key in tst_keys:\n",
    "            \n",
    "            best_ddqn_agent.set_environment(env)              \n",
    "            best_ddqn_agent.test(start_idx = testing_range[0],\n",
    "                        end_idx = testing_range[1], \n",
    "                        testing_episodes=1)\n",
    "\n",
    "            ## Save Test Metric Result(s) into \n",
    "            ddqn_tst = best_ddqn_agent.get_testing_episodic_data()\n",
    "            score = ddqn_tst['Total Reward'].mean()\n",
    "            scores.append(score)\n",
    "    \n",
    "            ## Export Test data\n",
    "            a = env.get_step_data()\n",
    "            b = best_ddqn_agent.get_step_data()\n",
    "            combined_df = pd.concat([a,b],axis=1)\n",
    "            tst_df_file_name  = f'TST-{key}' + test_name + '.csv'\n",
    "            trn_df_save_path = test_name_path + '/' + tst_df_file_name\n",
    "            combined_df.to_csv(trn_df_save_path)\n",
    "\n",
    "            ## Generate Trading Graphic\n",
    "            tst_graph_file_name = trn_df_save_path[:-4] + '.png'\n",
    "            agentperform.agent_stock_performance(env.stock_price_data[testing_range[0]:testing_range[1]],\n",
    "                                                combined_df['Env Action'].to_numpy(),\n",
    "                                                key,\n",
    "                                                best_ddqn_agent.get_name(),\n",
    "                                                display_graph=True,\n",
    "                                                save_graphic=True,\n",
    "                                                path_file=tst_graph_file_name)\n",
    "\n",
    "    mean = np.mean(scores)\n",
    "    return mean\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best value: \", study.best_value)\n",
    "print(\"Best params: \", study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MADDQN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
